{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H__KTa0RNQDo",
        "outputId": "94fa9e27-99d0-46a6-b8b5-178a1cd96c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#!pip install torchviz\n",
        "# !pip install tsf\n",
        "\n",
        "\n",
        "import h5py\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy\n",
        "import statistics\n",
        "from numpy import loadtxt\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statistics import stdev\n",
        "import math\n",
        "import h5py\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from scipy.signal import butter,filtfilt\n",
        "import sys\n",
        "import numpy as np # linear algebra\n",
        "from scipy.stats import randint\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
        "import matplotlib.pyplot as plt # this is used for the plot the graph\n",
        "import seaborn as sns # used for plot interactive graph.\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# from tsf.model import TransformerForecaster\n",
        "\n",
        "\n",
        "# from tensorflow.keras.utils import np_utils\n",
        "import itertools\n",
        "###  Library for attention layers\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "#from tqdm import tqdm # Processing time measurement\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import statistics\n",
        "import gc\n",
        "import torch.nn.init as init\n",
        "\n",
        "############################################################################################################################################################################\n",
        "############################################################################################################################################################################\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.utils.weight_norm as weight_norm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "#from torchsummary import summary\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "#from torchsummary import summary\n",
        "\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "import gc\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZUqAOjdHjNS"
      },
      "outputs": [],
      "source": [
        "#example file path to vicon data from google drive\n",
        "file_path = \"/content/drive/My Drive/vicon\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tbRyus4s18s"
      },
      "outputs": [],
      "source": [
        "#to delete data produced by datasharding function\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "yes_delete = False\n",
        "\n",
        "if yes_delete:\n",
        "    # Example path to the folder you want to delete\n",
        "    folder_path = '/content/datasets'\n",
        "    # Delete the folder and its contents recursively\n",
        "    shutil.rmtree(folder_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrXnoV0Js5CO"
      },
      "source": [
        "# File path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mq0s3oBqlJ5"
      },
      "source": [
        "# Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiUpSvBQezWo"
      },
      "outputs": [],
      "source": [
        "# Index 0: pelvis_tilt\n",
        "# Index 1: pelvis_list\n",
        "# Index 2: pelvis_rotation\n",
        "# Index 3: pelvis_tx\n",
        "# Index 4: pelvis_ty\n",
        "# Index 5: pelvis_tz\n",
        "# Index 6: hip_flexion_r\n",
        "# Index 7: hip_adduction_r\n",
        "# Index 8: hip_rotation_r\n",
        "# Index 9: knee_angle_r\n",
        "# Index 10: knee_angle_r_beta\n",
        "# Index 11: ankle_angle_r\n",
        "# Index 12: subtalar_angle_r\n",
        "# Index 13: mtp_angle_r\n",
        "# Index 14: hip_flexion_l\n",
        "# Index 15: hip_adduction_l\n",
        "# Index 16: hip_rotation_l\n",
        "# Index 17: knee_angle_l\n",
        "# Index 18: knee_angle_l_beta\n",
        "# Index 19: ankle_angle_l\n",
        "# Index 20: subtalar_angle_l\n",
        "# Index 21: mtp_angle_l\n",
        "# Index 22: lumbar_extension\n",
        "# Index 23: lumbar_bending\n",
        "# Index 24: lumbar_rotation\n",
        "# Index 25: arm_flex_r\n",
        "# Index 26: arm_add_r\n",
        "# Index 27: arm_rot_r\n",
        "# Index 28: elbow_flex_r\n",
        "# Index 29: pro_sup_r\n",
        "# Index 30: wrist_flex_r\n",
        "# Index 31: wrist_dev_r\n",
        "# Index 32: arm_flex_l\n",
        "# Index 33: arm_add_l\n",
        "# Index 34: arm_rot_l\n",
        "# Index 35: elbow_flex_l\n",
        "# Index 36: pro_sup_l\n",
        "# Index 37: wrist_flex_l\n",
        "# Index 38: wrist_dev_l\n",
        "# Index 39: time\n",
        "# Index 40: 1\n",
        "# Index 41: IM EMG1\n",
        "# Index 42: IM EMG2\n",
        "# Index 43: IM EMG3\n",
        "# Index 44: IM EMG4\n",
        "# Index 45: IM EMG5\n",
        "# Index 46: IM EMG6\n",
        "# Index 47: IM EMG7\n",
        "# Index 48: IM EMG8\n",
        "# Index 49: ACCX1\n",
        "# Index 50: ACCY1\n",
        "# Index 51: ACCZ1\n",
        "# Index 52: GYROX1\n",
        "# Index 53: GYROY1\n",
        "# Index 54: GYROZ1\n",
        "# Index 55: ACCX2\n",
        "# Index 56: ACCY2\n",
        "# Index 57: ACCZ2\n",
        "# Index 58: GYROX2\n",
        "# Index 59: GYROY2\n",
        "# Index 60: GYROZ2\n",
        "# Index 61: ACCX3\n",
        "# Index 62: ACCY3\n",
        "# Index 63: ACCZ3\n",
        "# Index 64: GYROX3\n",
        "# Index 65: GYROY3\n",
        "# Index 66: GYROZ3\n",
        "# Index 67: ACCX4\n",
        "# Index 68: ACCY4\n",
        "# Index 69: ACCZ4\n",
        "# Index 70: GYROX4\n",
        "# Index 71: GYROY4\n",
        "# Index 72: GYROZ4\n",
        "# Index 73: ACCX5\n",
        "# Index 74: ACCY5\n",
        "# Index 75: ACCZ5\n",
        "# Index 76: GYROX5\n",
        "# Index 77: GYROY5\n",
        "# Index 78: GYROZ5\n",
        "# Index 79: ACCX6\n",
        "# Index 80: ACCY6\n",
        "# Index 81: ACCZ6\n",
        "# Index 82: GYROX6\n",
        "# Index 83: GYROY6\n",
        "# Index 84: GYROZ6\n",
        "# Index 85: ACCX7\n",
        "# Index 86: ACCY7\n",
        "# Index 87: ACCZ7\n",
        "# Index 88: GYROX7\n",
        "# Index 89: GYROY7\n",
        "# Index 90: GYROZ7\n",
        "# Index 91: ACCX8\n",
        "# Index 92: ACCY8\n",
        "# Index 93: ACCZ8\n",
        "# Index 94: GYROX8\n",
        "# Index 95: GYROY8\n",
        "# Index 96: GYROZ8\n",
        "\n",
        "columns_imu_acc = ['ACCX1', 'ACCY1', 'ACCZ1','ACCX2', 'ACCY2', 'ACCZ2','ACCX3', 'ACCY3', 'ACCZ3','ACCX4', 'ACCY4', 'ACCZ4','ACCX5', 'ACCY5', 'ACCZ5', 'ACCX6', 'ACCY6', 'ACCZ6','ACCX7', 'ACCY7', 'ACCZ7', 'ACCX8', 'ACCY8', 'ACCZ8']\n",
        "\n",
        "#made due to difference in subject 1 and subject 2 data\n",
        "columns_imu_acc_test = ['ACCX1', 'ACCY1', 'ACCZ1','ACCX2', 'ACCY2', 'ACCZ2','ACCX3', 'ACCY3', 'ACCZ3','ACCX4', 'ACCY4', 'ACCZ4','ACCX5', 'ACCY5', 'ACCZ5', 'ACCX6', 'ACCY6', 'ACCZ6','ACCX10', 'ACCY10', 'ACCZ10']\n",
        "\n",
        "columns_imu_gyr = ['GYROX1', 'GYROY1', 'GYROZ1','GYROX2', 'GYROY2', 'GYROZ2','GYROX3', 'GYROY3', 'GYROZ3','GYROX4', 'GYROY4', 'GYROZ4','GYROX5', 'GYROY5', 'GYROZ5', 'GYROX6', 'GYROY6', 'GYROZ6','GYROX7', 'GYROY7', 'GYROZ7', 'GYROX8', 'GYROY8', 'GYROZ8']\n",
        "\n",
        "#made due to difference in subject 1 and subject 2 data\n",
        "columns_imu_gyr_test = ['GYROX1', 'GYROY1', 'GYROZ1','GYROX2', 'GYROY2', 'GYROZ2', 'GYROX3', 'GYROY3', 'GYROZ3','GYROX4', 'GYROY4', 'GYROZ4','GYROX5', 'GYROY5', 'GYROZ5', 'GYROX6', 'GYROY6', 'GYROZ6', 'GYROX10', 'GYROY10', 'GYROZ10']\n",
        "\n",
        "columns_joints = ['elbow_flex_r', 'arm_flex_r', 'arm_rot_r']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQO6FBR5e0M8"
      },
      "outputs": [],
      "source": [
        "#CONFIG\n",
        "\n",
        "class config_general:\n",
        "    #device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        self.batch_size = kwargs.get('batch_size', 16)\n",
        "        self.epochs = kwargs.get('epochs', 10)\n",
        "        self.lr = kwargs.get('lr', 0.001)\n",
        "        self.scheduler = kwargs.get('scheduler', None)\n",
        "        self.channels_imu_acc = kwargs.get('channels_imu_acc', None)\n",
        "        self.channels_imu_acc_test = kwargs.get('channels_imu_acc_test', None)\n",
        "        self.channels_imu_gyr_test = kwargs.get('channels_imu_gyr_test', None)\n",
        "        self.channels_imu_gyr = kwargs.get('channels_imu_gyr', None)\n",
        "        self.channels_joints = kwargs.get('channels_joints', None)\n",
        "        self.channels_emg = kwargs.get('channels_emg', None)\n",
        "        self.num_sessions = kwargs.get('num_sessions', None)\n",
        "        self.num_patients = kwargs.get('num_patients', None)\n",
        "        self.seed = kwargs.get('seed', 42)\n",
        "        self.data_folder_name = kwargs.get('data_folder_name', 'default_data_folder_name')\n",
        "        self.dataset_root = kwargs.get('dataset_root', 'default_dataset_root')\n",
        "        self.dataset_train_name = kwargs.get('dataset_train_name', 'train')\n",
        "        self.dataset_test_name = kwargs.get('dataset_test_name', 'test')\n",
        "        self.dataset_name = kwargs.get('dataset_name', 'default_dataset_name')\n",
        "        self.window_length = kwargs.get('window_length', 100)\n",
        "        self.window_overlap = kwargs.get('window_overlap', 0)\n",
        "        self.imu_transforms = kwargs.get('imu_transforms', [])\n",
        "        self.joint_transforms = kwargs.get('joint_transforms', [])\n",
        "        self.emg_transforms = kwargs.get('emg_transforms', [])\n",
        "        self.hidden_size = kwargs.get('hidden_size', 256)\n",
        "        self.num_layers = kwargs.get('num_layers', 6)\n",
        "        self.input_size = kwargs.get('input_size', 3)\n",
        "        self.output_size = kwargs.get('output_size', 3)\n",
        "        self.sample_rate =kwargs.get('sample_rate', 100)\n",
        "        self.input_format =  kwargs.get('input_format', 'vicon') # csv or wav\n",
        "\n",
        "        hyperparameters = [\n",
        "            f\"batch_size_{self.batch_size}\",\n",
        "            f\"epochs_{self.epochs}\",\n",
        "            f\"lr_{self.lr}\",\n",
        "            f\"scheduler_{self.scheduler}\",\n",
        "            f\"channels_imu_gyr_{self.channels_imu_gyr}\",\n",
        "            f\"channels_imu_acctest__{self.channels_imu_acc_test}\",\n",
        "            f\"channels_imu_acc_{self.channels_imu_acc}\",\n",
        "            f\"channels_imu_gyr_test_{self.channels_imu_gyr_test}\",\n",
        "            f\"channels_joints_{self.channels_joints}\",\n",
        "            f\"channels_emg_{self.channels_emg}\",\n",
        "            f\"num_sessions_{self.num_sessions}\",\n",
        "            f\"num_patients_{self.num_patients}\",\n",
        "            f\"seed_{self.seed}\",\n",
        "            f\"data_folder_name_{self.data_folder_name}\",\n",
        "            f\"dataset_root_{self.dataset_root}\",\n",
        "            f\"dataset_train_name_{self.dataset_train_name}\",\n",
        "            f\"dataset_test_name_{self.dataset_test_name}\",\n",
        "            f\"window_length_{self.window_length}\",\n",
        "            f\"imu_transforms_{self.imu_transforms}\",\n",
        "            f\"joint_transforms_{self.joint_transforms}\",\n",
        "            f\"emg_transforms_{self.emg_transforms}\",\n",
        "            f\"hidden_size_{self.hidden_size}\",\n",
        "            f\"num_layers_{self.num_layers}\",\n",
        "            f\"input_size_{self.input_size}\",\n",
        "            f\"output_size_{self.output_size}\",\n",
        "            f\"sample_rate_{self.sample_rate}\",\n",
        "            f\"input_format_{self.input_format}\"\n",
        "        ]\n",
        "\n",
        "        self.hyperparameters_str = \"_\".join(map(str, hyperparameters))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDCp1y6Cf-XV"
      },
      "outputs": [],
      "source": [
        "#FUNCTION TO RETRIEVE DATA FROM WAV FILES\n",
        "from scipy.io import wavfile\n",
        "\n",
        "def get_data_from_wav_file(filename): #return data shape [time_steps,channels]\n",
        "        sample_rate, data = wavfile.read(filename)\n",
        "        # print(f\"Sample rate: {sample_rate}Hz|Data shape: {data.shape}\")\n",
        "        return data, sample_rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWhaC2o4fnIj"
      },
      "outputs": [],
      "source": [
        "#USE CONFIG\n",
        "\n",
        "config = config_general(\n",
        "    data_folder_name=\"/content/drive/My Drive/vicon\",\n",
        "    dataset_root=\"datasets\",\n",
        "    dataset_name=\"two_subject\",\n",
        "    window_length=100,\n",
        "    window_overlap=50,\n",
        "    input_format=\"csv\",\n",
        "    num_patients=2,\n",
        "    channels_imu_acc= columns_imu_acc,  # Column name for accelerometer data in CSV\n",
        "    channels_imu_acc_test=columns_imu_acc_test,  # Column name for accelerometer data in CSV\n",
        "    channels_imu_gyr_test=columns_imu_gyr_test,  # Column name for gyroscope data in CSV\n",
        "    channels_imu_gyr=columns_imu_gyr,  # Column name for gyroscope data in CSV\n",
        "    channels_joints=columns_joints,  # Column name for joint data in CSV\n",
        "    channels_emg=['IM EMG1', 'IM EMG2', 'IM EMG3', 'IM EMG4', 'IM EMG5', 'IM EMG6', 'IM EMG7', 'IM EMG8'],\n",
        "    imu_transforms=[],\n",
        "    joint_transforms=[],\n",
        "    emg_transforms=[]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpbgP3x7fOes"
      },
      "outputs": [],
      "source": [
        "#DATASHARDER\n",
        "\n",
        "class DataSharder:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.sample_rate = config.sample_rate\n",
        "        self.input_format = config.input_format\n",
        "        self.data_folder_path = config.data_folder_name\n",
        "        self.window_length = int(config.window_length)  # Ensure window_size is an integer\n",
        "        self.window_overlap = int(config.window_overlap)  # Ensure overlap is an integer\n",
        "        self.num_patients = int(config.num_patients)  # Ensure num_patients is an integer\n",
        "\n",
        "    def load_data(self):\n",
        "        patient_folders_list = [f for f in os.listdir(self.data_folder_path) if os.path.isdir(os.path.join(self.data_folder_path, f))]\n",
        "        training_patients = patient_folders_list[:self.num_patients-1]\n",
        "        testing_patients = patient_folders_list[self.num_patients-1:]\n",
        "\n",
        "        if self.input_format == 'wav':\n",
        "            self._process_and_save_patients_wav(training_patients, \"train\")\n",
        "            self._process_and_save_patients_wav(testing_patients, \"test\")\n",
        "        elif self.input_format == 'csv':\n",
        "            self._process_and_save_patients_csv(training_patients, \"train\")\n",
        "            self._process_and_save_patients_csv(testing_patients, \"test\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported input format: {self.input_format}\")\n",
        "\n",
        "    #ask oliver if he can split data into acc and gyr for imu\n",
        "    def _process_and_save_patients_wav(self, patient_id_list, split):\n",
        "        for patient_id in tqdm(patient_id_list, desc=f\"Processing {split} patients\"):\n",
        "            for session_index in tqdm(range(self.config.num_sessions), desc=f\"Processing sessions for {patient_id}\", leave=False):\n",
        "                imu_data, imu_sample_rate = self._load_wav_file(patient_id, session_index, \"IMU\")\n",
        "                joints_data, joints_sample_rate = self._load_wav_file(patient_id, session_index, \"JOINTS\")\n",
        "                emg_data, emg_sample_rate = self._load_wav_file(patient_id, session_index, \"EMG\")\n",
        "\n",
        "                imu_data = self._resample_data(imu_data, imu_sample_rate)\n",
        "                joints_data = self._resample_data(joints_data, joints_sample_rate)\n",
        "                emg_data = self._resample_data(emg_data, emg_sample_rate)\n",
        "\n",
        "                combined_data = torch.cat((imu_data, joints_data, emg_data), dim=1)\n",
        "                self._save_windowed_data(combined_data, patient_id, session_index, split)\n",
        "\n",
        "    def _load_wav_file(self, patient_id, session_index, file_type):\n",
        "        file_path = os.path.join(self.data_folder_path, patient_id, f\"run{session_index}_{file_type}.wav\")\n",
        "        data, sample_rate = get_data_from_wav_file(file_path)\n",
        "        return torch.tensor(data, dtype=torch.float32), sample_rate\n",
        "\n",
        "    def _resample_data(self, data, sample_rate):\n",
        "        if sample_rate != self.sample_rate:\n",
        "            data = T.Resample(sample_rate, self.sample_rate)(data.T).T\n",
        "        return data\n",
        "\n",
        "    def _process_and_save_patients_csv(self, patient_id_list, split):\n",
        "        for patient_id in tqdm(patient_id_list, desc=f\"Processing {split} patients\"):\n",
        "            patient_files = os.listdir(os.path.join(self.data_folder_path, patient_id, \"combined\"))\n",
        "            for session_file in tqdm(patient_files, desc=f\"Processing sessions for {patient_id}\", leave=False):\n",
        "                data = pd.read_csv(os.path.join(self.data_folder_path, patient_id, \"combined\", session_file))\n",
        "                self._save_windowed_data(data, patient_id, session_file.split('.')[0], split, is_csv=True)\n",
        "\n",
        "    def _save_windowed_data(self, data, patient_id, session_id, split, is_csv=False):\n",
        "        dataset_name = f\"{self.config.dataset_name}_wl{self.window_length}_ol{self.window_overlap}_np{self.num_patients}\"\n",
        "        dataset_folder = os.path.join(self.config.dataset_root, dataset_name, self.config.dataset_train_name if split == \"train\" else self.config.dataset_test_name)\n",
        "        os.makedirs(dataset_folder, exist_ok=True)\n",
        "\n",
        "        window_size = self.window_length\n",
        "        overlap = self.window_overlap\n",
        "        step_size = window_size - overlap\n",
        "\n",
        "        data_info_list = []\n",
        "\n",
        "        for i in tqdm(range(0, len(data) - window_size + 1, step_size), desc=f\"Windowing data for {patient_id}_{session_id}\", leave=False):\n",
        "            windowed_data = data.iloc[i:i+window_size] if is_csv else data[i:i+window_size]\n",
        "            if windowed_data.shape[0] < window_size:\n",
        "                continue\n",
        "\n",
        "            windowed_data_np = windowed_data.to_numpy() if is_csv else windowed_data.cpu().numpy()\n",
        "            file_name = f\"{patient_id}_session_{session_id}_window_{i}_ws{window_size}_ol{overlap}.csv\"\n",
        "            file_path = os.path.join(dataset_folder, file_name)\n",
        "            pd.DataFrame(windowed_data_np, columns=data.columns if is_csv else None).to_csv(file_path, index=False)\n",
        "            data_info_list.append({\"file_name\": file_name, \"file_path\": file_path})\n",
        "\n",
        "        data_info_df = pd.DataFrame(data_info_list)\n",
        "        data_info_df.to_csv(os.path.join(self.config.dataset_root, dataset_name, f\"{split}_info.csv\"), index=False, mode='a', header=not os.path.exists(os.path.join(self.config.dataset_root, dataset_name, f\"{split}_info.csv\")))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vmukon1yferj"
      },
      "outputs": [],
      "source": [
        "#USE DATASHARDER\n",
        "reshard_data = True\n",
        "if reshard_data:\n",
        "    data_sharder = DataSharder(config)\n",
        "    data_sharder.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM9iGjQ6uXU-"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3Az_GyVSh8JC"
      },
      "outputs": [],
      "source": [
        "#DATASET OBJECT\n",
        "from torchvision.transforms import ToTensor\n",
        "import joblib\n",
        "\n",
        "class ImuJointPairDataset(Dataset):\n",
        "    def __init__(self, config, split='train'):\n",
        "        self.config = config\n",
        "        self.split = split\n",
        "        self.input_format = config.input_format\n",
        "        self.channels_imu_acc = config.channels_imu_acc\n",
        "        self.channels_imu_acc_test = config.channels_imu_acc_test\n",
        "        self.channels_imu_gyr = config.channels_imu_gyr\n",
        "        self.channels_imu_gyr_test = config.channels_imu_gyr_test\n",
        "        self.channels_joints = config.channels_joints\n",
        "        self.channels_emg = config.channels_emg\n",
        "\n",
        "        # Ensure the dataset name includes the window length, overlap, and num patients\n",
        "        dataset_name = f\"{self.config.dataset_name}_wl{self.config.window_length}_ol{self.config.window_overlap}_np{self.config.num_patients}\"\n",
        "        #print(\"folder with train data and test data: \", dataset_name)\n",
        "        self.root_dir_train = os.path.join(self.config.dataset_root, dataset_name, self.config.dataset_train_name)\n",
        "        self.root_dir_test = os.path.join(self.config.dataset_root, dataset_name, self.config.dataset_test_name)\n",
        "\n",
        "        # Load the info CSV files for the training and testing datasets\n",
        "        train_info_path = os.path.join(self.config.dataset_root, dataset_name, \"train_info.csv\")\n",
        "        test_info_path = os.path.join(self.config.dataset_root, dataset_name, \"test_info.csv\")\n",
        "        #print(\"train path: \", train_info_path)\n",
        "        #print(\"test path: \", test_info_path)\n",
        "\n",
        "        self.data = pd.read_csv(train_info_path) if split == 'train' else pd.read_csv(test_info_path)\n",
        "        #print(\"data: \", self.data)\n",
        "        # Define the path for saving the scaler\n",
        "        self.scaler_save_path = os.path.join(self.config.dataset_root, dataset_name, \"scaler.pkl\")\n",
        "\n",
        "        print(\"scaler path: \", self.scaler_save_path)\n",
        "        # Initialize and fit/load the scaler using the training data\n",
        "        #if os.path.exists(self.scaler_save_path):\n",
        "            #self.scaler = joblib.load(self.scaler_save_path)\n",
        "        if split == 'train':\n",
        "            self.scaler = StandardScaler()\n",
        "            self._fit_scaler(train_info_path)\n",
        "        elif split == 'test':\n",
        "            self.scaler = StandardScaler()\n",
        "            self._fit_scaler(test_info_path)\n",
        "        else:\n",
        "            raise FileNotFoundError(\"Scaler not found. Ensure you run the training split first to fit and save the scaler.\")\n",
        "\n",
        "    def _fit_scaler(self, train_info_path):\n",
        "        all_data = []\n",
        "        train_info = pd.read_csv(train_info_path)\n",
        "        if self.split == \"train\":\n",
        "            for idx in range(len(train_info)):\n",
        "                file_path = os.path.join(self.root_dir_train, train_info.iloc[idx, 0])\n",
        "                #print(\"file path: \", file_path)\n",
        "                if self.input_format == \"csv\":\n",
        "                    combined_data = pd.read_csv(file_path)\n",
        "                    imu_data_acc = combined_data[self.channels_imu_acc].values\n",
        "                    imu_data_gyr = combined_data[self.channels_imu_gyr].values\n",
        "                    joint_data = combined_data[self.channels_joints].values\n",
        "                    emg_data = combined_data[self.channels_emg].values\n",
        "                    all_data.append(np.concatenate([imu_data_acc, imu_data_gyr, joint_data, emg_data], axis=1))  # Concatenate along axis 1 (channels)\n",
        "\n",
        "        else:\n",
        "            for idx in range(len(train_info)):\n",
        "                file_path = os.path.join(self.root_dir_test, train_info.iloc[idx, 0])\n",
        "                #print(\"file path: \", file_path)\n",
        "                if self.input_format == \"csv\":\n",
        "                    combined_data = pd.read_csv(file_path)\n",
        "                    imu_data_acc = combined_data[self.channels_imu_acc_test].values\n",
        "                    imu_data_gyr = combined_data[self.channels_imu_gyr_test].values\n",
        "                    joint_data = combined_data[self.channels_joints].values\n",
        "                    emg_data = combined_data[self.channels_emg].values\n",
        "                    all_data.append(np.concatenate([imu_data_acc, imu_data_gyr, joint_data, emg_data], axis=1))  # Concatenate along axis 1 (channels)\n",
        "\n",
        "        all_data = np.vstack(all_data)  # Stack along axis 0 (time)\n",
        "        self.scaler.fit(all_data)\n",
        "\n",
        "        # Save the scaler for later use\n",
        "        os.makedirs(os.path.dirname(self.scaler_save_path), exist_ok=True)\n",
        "        joblib.dump(self.scaler, self.scaler_save_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Access to either train or test dataset\n",
        "        if self.split == \"train\":\n",
        "            #print(\"train chosen: \", self.root_dir_train, self.data.iloc[idx, 0])\n",
        "            file_path = os.path.join(self.root_dir_train, self.data.iloc[idx, 0])\n",
        "        else:\n",
        "            print(\"test chosen: \", self.root_dir_test, self.data.iloc[idx, 0])\n",
        "            file_path = os.path.join(self.root_dir_test, self.data.iloc[idx, 0])\n",
        "\n",
        "        #print(\"chosen file path: \", file_path)\n",
        "\n",
        "        # Check if the input format is CSV or WAV and load the data accordingly\n",
        "        #print(\"input format: \", self.input_format)\n",
        "        if self.input_format == \"wav\":\n",
        "            combined_data, _ = get_data_from_wav_file(file_path)\n",
        "        elif self.input_format == \"csv\":\n",
        "            combined_data = pd.read_csv(file_path)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported input format: {}\".format(self.input_format))\n",
        "\n",
        "        if self.split =='train':\n",
        "            # IMU acc\n",
        "            if isinstance(self.channels_imu_acc, slice):\n",
        "                imu_data_acc = combined_data.iloc[:, self.channels_imu_acc].values if self.input_format == \"csv\" else combined_data[:, self.channels_imu_acc]\n",
        "            else:\n",
        "                imu_data_acc = combined_data[self.channels_imu_acc].values if self.input_format == \"csv\" else combined_data[:, self.channels_imu_acc]\n",
        "\n",
        "            # IMU gyro\n",
        "            if isinstance(self.channels_imu_gyr, slice):\n",
        "                imu_data_gyr = combined_data.iloc[:, self.channels_imu_gyr].values if self.input_format == \"csv\" else combined_data[:, self.channels_imu_gyr]\n",
        "            else:\n",
        "                imu_data_gyr = combined_data[self.channels_imu_gyr].values if self.input_format == \"csv\" else combined_data[:, self.channels_imu_gyr]\n",
        "\n",
        "            # JOINT\n",
        "            if isinstance(self.channels_joints, slice):\n",
        "                joint_data = combined_data.iloc[:, self.channels_joints].values if self.input_format == \"csv\" else combined_data[:, self.channels_joints]\n",
        "            else:\n",
        "                joint_data = combined_data[self.channels_joints].values if self.input_format == \"csv\" else combined_data[:, self.channels_joints]\n",
        "\n",
        "            #EMG\n",
        "            if isinstance(self.channels_emg, slice):\n",
        "                emg_data = combined_data.iloc[:, self.channels_emg].values if self.input_format == \"csv\" else combined_data[:, self.channels_emg]\n",
        "            else:\n",
        "                emg_data = combined_data[self.channels_emg].values if self.input_format == \"csv\" else combined_data[:, self.channels_emg]\n",
        "\n",
        "            # Combine IMU, Joint and EMG data for scaling\n",
        "            #print(\"imu_data_acc shape: \", imu_data_acc.shape)\n",
        "            #print(\"imu_data_gyr shape: \", imu_data_gyr.shape)\n",
        "            #print(\"joint_data shape: \", joint_data.shape)\n",
        "            #print(\"emg_data shape: \", emg_data.shape)\n",
        "            combined_data = np.concatenate([imu_data_acc, imu_data_gyr, joint_data, emg_data], axis=1)  # Concatenate along axis 1 (channels)\n",
        "            #print(\"combined_data shape: \", combined_data.shape)\n",
        "            # Scale the data\n",
        "            scaled_data = self.scaler.transform(combined_data)\n",
        "            #print(\"scaled_data shape: \", scaled_data.shape)\n",
        "\n",
        "            # Separate the scaled data back into IMU and Joint\n",
        "            imu_data_acc = scaled_data[:, :imu_data_acc.shape[1]]\n",
        "            imu_data_gyr = scaled_data[:, imu_data_acc.shape[1]:imu_data_acc.shape[1]+imu_data_gyr.shape[1]]#CHECK\n",
        "            joint_data = scaled_data[:, imu_data_gyr.shape[1]:imu_data_gyr.shape[1]+len(self.channels_joints)]\n",
        "            emg_data = scaled_data[:,imu_data_acc.shape[1]:imu_data_gyr.shape[1]+len(self.channels_emg)] #CHECK\n",
        "\n",
        "            # Apply transformations\n",
        "            imu_data_acc = self.apply_transforms(imu_data_acc, self.config.imu_transforms)\n",
        "            imu_data_gyr = self.apply_transforms(imu_data_gyr, self.config.imu_transforms)\n",
        "            joint_data = self.apply_transforms(joint_data, self.config.joint_transforms)\n",
        "            emg_data = self.apply_transforms(emg_data, self.config.emg_transforms)\n",
        "\n",
        "            return imu_data_acc, imu_data_gyr, joint_data, emg_data\n",
        "\n",
        "        else:\n",
        "            # IMU acc\n",
        "            if isinstance(self.channels_imu_acc_test, slice):\n",
        "                imu_data_acc = combined_data.iloc[:, self.channels_imu_acc_test].values if self.input_format == \"csv\" else combined_data[:, self.channels_imu_acc_test]\n",
        "            else:\n",
        "                imu_data_acc = combined_data[self.channels_imu_acc_test].values if self.input_format == \"csv\" else combined_data[:, self.channels_imu_acc_test]\n",
        "\n",
        "            # IMU gyro\n",
        "            if isinstance(self.channels_imu_gyr_test, slice):\n",
        "                imu_data_gyr = combined_data.iloc[:, self.channels_imu_gyr_test].values if self.input_format == \"csv\" else combined_data[:, self.channels_imu_gyr_test]\n",
        "            else:\n",
        "                imu_data_gyr = combined_data[self.channels_imu_gyr_test].values if self.input_format == \"csv\" else combined_data[:, self.channels_imu_gyr_test]\n",
        "\n",
        "            # JOINT\n",
        "            if isinstance(self.channels_joints, slice):\n",
        "                joint_data = combined_data.iloc[:, self.channels_joints].values if self.input_format == \"csv\" else combined_data[:, self.channels_joints]\n",
        "            else:\n",
        "                joint_data = combined_data[self.channels_joints].values if self.input_format == \"csv\" else combined_data[:, self.channels_joints]\n",
        "\n",
        "            #EMG\n",
        "            if isinstance(self.channels_emg, slice):\n",
        "                emg_data = combined_data.iloc[:, self.channels_emg].values if self.input_format == \"csv\" else combined_data[:, self.channels_emg]\n",
        "            else:\n",
        "                emg_data = combined_data[self.channels_emg].values if self.input_format == \"csv\" else combined_data[:, self.channels_emg]\n",
        "\n",
        "            # Combine IMU, Joint and EMG data for scaling\n",
        "            #print(\"imu_data_acc shape: \", imu_data_acc.shape)\n",
        "            #print(\"imu_data_gyr shape: \", imu_data_gyr.shape)\n",
        "            #print(\"joint_data shape: \", joint_data.shape)\n",
        "            #print(\"emg_data shape: \", emg_data.shape)\n",
        "            combined_data = np.concatenate([imu_data_acc, imu_data_gyr, joint_data, emg_data], axis=1)  # Concatenate along axis 1 (channels)\n",
        "            #print(\"combined_data shape: \", combined_data.shape)\n",
        "            # Scale the data\n",
        "            scaled_data = self.scaler.transform(combined_data)\n",
        "            #print(\"scaled_data shape: \", scaled_data.shape)\n",
        "\n",
        "            # Separate the scaled data back into IMU and Joint\n",
        "            imu_data_acc = scaled_data[:, :imu_data_acc.shape[1]]\n",
        "            imu_data_gyr = scaled_data[:, imu_data_acc.shape[1]:imu_data_acc.shape[1]+imu_data_gyr.shape[1]]#CHECK\n",
        "            joint_data = scaled_data[:, imu_data_gyr.shape[1]:imu_data_gyr.shape[1]+len(self.channels_joints)]\n",
        "            emg_data = scaled_data[:,imu_data_acc.shape[1]:imu_data_gyr.shape[1]+len(self.channels_emg)] #CHECK\n",
        "\n",
        "            # Apply transformations\n",
        "            imu_data_acc = self.apply_transforms(imu_data_acc, self.config.imu_transforms)\n",
        "            imu_data_gyr = self.apply_transforms(imu_data_gyr, self.config.imu_transforms)\n",
        "            joint_data = self.apply_transforms(joint_data, self.config.joint_transforms)\n",
        "            emg_data = self.apply_transforms(emg_data, self.config.emg_transforms)\n",
        "\n",
        "            return imu_data_acc, imu_data_gyr, joint_data, emg_data\n",
        "\n",
        "    # Function to apply transforms\n",
        "    def apply_transforms(self, data, transforms):\n",
        "        for transform in transforms:\n",
        "            data = transform(data)\n",
        "\n",
        "        data = ToTensor()(data).squeeze(0)\n",
        "        return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aw26Xu4O75I"
      },
      "outputs": [],
      "source": [
        "#check folder contents\n",
        "import os\n",
        "\n",
        "# Specify the path to the folder you want to list\n",
        "folder_path = 'datasets/two_subject_wl100_ol50_np2/train'\n",
        "\n",
        "# List the contents of the folder\n",
        "contents = os.listdir(folder_path)\n",
        "\n",
        "# Print the contents\n",
        "print(\"Contents of the folder:\")\n",
        "for item in contents:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mfy6CoGFgNL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce5e1be6-cc5c-4013-9b24-4ef95389e0de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scaler path:  datasets/two_subject_wl100_ol50_np2/scaler.pkl\n",
            "torch.Size([100, 24]) torch.Size([100, 24]) torch.Size([100, 3]) torch.Size([100, 8])\n",
            "scaler path:  datasets/two_subject_wl100_ol50_np2/scaler.pkl\n",
            "test chosen:  datasets/two_subject_wl100_ol50_np2/test subject2_session_P002_T001_armSwing_fast_combined_window_0_ws100_ol50.csv\n",
            "test chosen:  datasets/two_subject_wl100_ol50_np2/test subject2_session_P002_T001_armSwing_fast_combined_window_0_ws100_ol50.csv\n",
            "test chosen:  datasets/two_subject_wl100_ol50_np2/test subject2_session_P002_T001_armSwing_fast_combined_window_0_ws100_ol50.csv\n",
            "test chosen:  datasets/two_subject_wl100_ol50_np2/test subject2_session_P002_T001_armSwing_fast_combined_window_0_ws100_ol50.csv\n",
            "torch.Size([100, 21]) torch.Size([100, 21]) torch.Size([100, 3]) torch.Size([100, 8])\n"
          ]
        }
      ],
      "source": [
        "#create datasets\n",
        "train_dataset = ImuJointPairDataset(config, split='train')\n",
        "print(train_dataset.__getitem__(0)[0].shape, train_dataset.__getitem__(0)[1].shape, train_dataset.__getitem__(0)[2].shape, train_dataset.__getitem__(0)[3].shape)\n",
        "test_dataset = ImuJointPairDataset(config, split='test')\n",
        "print(test_dataset.__getitem__(0)[0].shape, test_dataset.__getitem__(0)[1].shape, test_dataset.__getitem__(0)[2].shape, test_dataset.__getitem__(0)[3].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hG79CDs2gOQD"
      },
      "outputs": [],
      "source": [
        "#setup validation dataset\n",
        "train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Uo_jxqLqgQ62"
      },
      "outputs": [],
      "source": [
        "#setup dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DY4UV4Lxgkxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86896124-603f-4505-ddf4-e2b8fb32ddcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: torch.Size([64, 100, 24]), torch.Size([64, 100, 24]), torch.Size([64, 100, 3]), torch.Size([64, 100, 8])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Get the first batch from the train loader\n",
        "data_acc, data_gyr, data_targets, data_emg = next(iter(train_loader))\n",
        "\n",
        "print(f\"Data shape: {data_acc.shape}, {data_gyr.shape}, {data_targets.shape}, {data_emg.shape}\")\n",
        "\n",
        "# Plot the first element in the train loader\n",
        "#plot_data_kinelight(x, y, config, test_dataset.scaler, \"Train\")\n",
        "\n",
        "# Optionally, plot the first element in the test loader\n",
        "#x_test, y_test = next(iter(test_loader))\n",
        "#plot_data_kinelight(x_test, y_test, config, test_dataset.scaler, \"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP_eDnJwrKCC"
      },
      "source": [
        "# Important Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RdVunLKprSkv"
      },
      "outputs": [],
      "source": [
        "#prediction function\n",
        "def RMSE_prediction(yhat_4,test_y, output_dim):\n",
        "\n",
        "  s1=yhat_4.shape[0]*yhat_4.shape[1]\n",
        "\n",
        "  test_o=test_y.reshape((s1,output_dim))\n",
        "  yhat=yhat_4.reshape((s1,output_dim))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  y_1_no=yhat[:,0]\n",
        "  y_2_no=yhat[:,1]\n",
        "  y_3_no=yhat[:,2]\n",
        "  #y_4_no=yhat[:,3]\n",
        "  #y_5_no=yhat[:,4]\n",
        "  #y_6_no=yhat[:,5]\n",
        "  #y_7_no=yhat[:,6]\n",
        "  #y_8_no=yhat[:,7]\n",
        "  #y_9_no=yhat[:,8]\n",
        "  #y_10_no=yhat[:,9]\n",
        "\n",
        "\n",
        "  y_1=y_1_no\n",
        "  y_2=y_2_no\n",
        "  y_3=y_3_no\n",
        "  #y_4=y_4_no\n",
        "  #y_5=y_5_no\n",
        "  #y_6=y_6_no\n",
        "  #y_7=y_7_no\n",
        "\n",
        "\n",
        "\n",
        "  y_test_1=test_o[:,0]\n",
        "  y_test_2=test_o[:,1]\n",
        "  y_test_3=test_o[:,2]\n",
        "  #y_test_4=test_o[:,3]\n",
        "  #y_test_5=test_o[:,4]\n",
        "  #y_test_6=test_o[:,5]\n",
        "  #y_test_7=test_o[:,6]\n",
        "  #y_test_8=test_o[:,7]\n",
        "  #y_test_9=test_o[:,8]\n",
        "  #y_test_10=test_o[:,9]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #print(y_1.shape,y_test_1.shape)\n",
        "\n",
        "\n",
        "  cutoff=6\n",
        "  fs=200\n",
        "  order=4\n",
        "\n",
        "  nyq = 0.5 * fs\n",
        "  ## filtering data ##\n",
        "  def butter_lowpass_filter(data, cutoff, fs, order):\n",
        "      normal_cutoff = cutoff / nyq\n",
        "      # Get the filter coefficients\n",
        "      b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "      y = filtfilt(b, a, data)\n",
        "      return y\n",
        "\n",
        "\n",
        "\n",
        "  # y_1=butter_lowpass_filter(y_1_no, cutoff, fs, order)\n",
        "  # y_2=butter_lowpass_filter(y_2_no, cutoff, fs, order)\n",
        "  # y_3=butter_lowpass_filter(y_3_no, cutoff, fs, order)\n",
        "  # y_4=butter_lowpass_filter(y_4_no, cutoff, fs, order)\n",
        "  # y_5=butter_lowpass_filter(y_5_no, cutoff, fs, order)\n",
        "  # y_6=butter_lowpass_filter(y_6_no, cutoff, fs, order)\n",
        "  # y_7=butter_lowpass_filter(y_7_no, cutoff, fs, order)\n",
        "  #y_8=butter_lowpass_filter(y_8_no, cutoff, fs, order)\n",
        "  #y_9=butter_lowpass_filter(y_9_no, cutoff, fs, order)\n",
        "  #y_10=butter_lowpass_filter(y_10_no, cutoff, fs, order)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  Z_1=y_1\n",
        "  Z_2=y_2\n",
        "  Z_3=y_3\n",
        "  #Z_4=y_4\n",
        "  #Z_5=y_5\n",
        "  #Z_6=y_6\n",
        "  #Z_7=y_7\n",
        "  #Z_8=y_8\n",
        "  #Z_9=y_9\n",
        "  #Z_10=y_10\n",
        "\n",
        "\n",
        "\n",
        "  ###calculate RMSE\n",
        "\n",
        "  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1)))/(max(y_test_1)-min(y_test_1)))*100\n",
        "  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2)))/(max(y_test_2)-min(y_test_2)))*100\n",
        "  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3)))/(max(y_test_3)-min(y_test_3)))*100\n",
        "  #rmse_4 =((np.sqrt(mean_squared_error(y_test_4,y_4)))/(max(y_test_4)-min(y_test_4)))*100\n",
        "  #rmse_5 =((np.sqrt(mean_squared_error(y_test_5,y_5)))/(max(y_test_5)-min(y_test_5)))*100\n",
        "  #rmse_6 =((np.sqrt(mean_squared_error(y_test_6,y_6)))/(max(y_test_6)-min(y_test_6)))*100\n",
        "  #rmse_7 =((np.sqrt(mean_squared_error(y_test_7,y_7)))/(max(y_test_7)-min(y_test_7)))*100\n",
        "  #rmse_8 =((np.sqrt(mean_squared_error(y_test_8,y_8)))/(max(y_test_8)-min(y_test_8)))*100\n",
        "  #rmse_9 =((np.sqrt(mean_squared_error(y_test_9,y_9)))/(max(y_test_9)-min(y_test_9)))*100\n",
        "  #rmse_10 =((np.sqrt(mean_squared_error(y_test_10,y_10)))/(max(y_test_10)-min(y_test_10)))*100\n",
        "\n",
        "\n",
        "  print(rmse_1)\n",
        "  print(rmse_2)\n",
        "  print(rmse_3)\n",
        "  #print(rmse_4)\n",
        "  #print(rmse_5)\n",
        "  #print(rmse_6)\n",
        "  #print(rmse_7)\n",
        "  #print(rmse_8)\n",
        "  #print(rmse_9)\n",
        "  #print(rmse_10)\n",
        "\n",
        "\n",
        "  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n",
        "  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n",
        "  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n",
        "  #p_4=np.corrcoef(y_4, y_test_4)[0, 1]\n",
        "  #p_5=np.corrcoef(y_5, y_test_5)[0, 1]\n",
        "  #p_6=np.corrcoef(y_6, y_test_6)[0, 1]\n",
        "  #p_7=np.corrcoef(y_7, y_test_7)[0, 1]\n",
        "  #p_8=np.corrcoef(y_8, y_test_8)[0, 1]\n",
        "  #p_9=np.corrcoef(y_9, y_test_9)[0, 1]\n",
        "  #p_10=np.corrcoef(y_10, y_test_10)[0, 1]\n",
        "\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(p_1)\n",
        "  print(p_2)\n",
        "  print(p_3)\n",
        "  #print(p_4)\n",
        "  #print(p_5)\n",
        "  #print(p_6)\n",
        "  #print(p_7)\n",
        "  #print(p_8)\n",
        "  #print(p_9)\n",
        "  #print(p_10)\n",
        "\n",
        "\n",
        "              ### Correlation ###\n",
        "  p=np.array([p_1,p_2,p_3])\n",
        "  #,p_4,p_5,p_6,p_7])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "\n",
        "  rmse=np.array([rmse_1,rmse_2,rmse_3])\n",
        "  #,rmse_4,rmse_5,rmse_6,rmse_7])\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "  m=statistics.mean(rmse)\n",
        "  SD=statistics.stdev(rmse)\n",
        "  print('Mean: %.3f' % m,'+/- %.3f' %SD)\n",
        "\n",
        "  m_c=statistics.mean(p)\n",
        "  SD_c=statistics.stdev(p)\n",
        "  print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n",
        "\n",
        "\n",
        "\n",
        "  return rmse, p, Z_1,Z_2,Z_3\n",
        "  #,Z_4,Z_5,Z_6,Z_7\n",
        "\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YhQKyL6ph4hD"
      },
      "outputs": [],
      "source": [
        "#RMSELoss\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        mse = nn.MSELoss()(pred, target)\n",
        "        rmse = torch.sqrt(mse)\n",
        "        return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "s5Q-cJ2tK8Vb"
      },
      "outputs": [],
      "source": [
        "#DEVICE\n",
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgJxMSflV52e"
      },
      "source": [
        "# Teacher Model Training -- IMU-EMG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FG-HuNBV52f"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "v0iJJkktV52f"
      },
      "outputs": [],
      "source": [
        "def train_mm_teacher(device, train_loader, val_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data_acc, data_gyr, target, data_EMG) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output,x_1= model(data_acc.to(device).float(),data_gyr.to(device).float(),data_EMG.to(device).float())\n",
        "\n",
        "            #print(output.shape,target.shape)\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for (data_acc, data_gyr, target, data_EMG) in val_loader:\n",
        "                output,x_1= model(data_acc.to(device).float(),data_gyr.to(device).float(),  data_EMG.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "endRpZEuDUdp"
      },
      "source": [
        "## Multi-Encoder Teacher Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Y0bdibsD_Ld2"
      },
      "outputs": [],
      "source": [
        "class Encoder_1(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_1, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder_2(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_2, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CYWS2knQJnoV"
      },
      "outputs": [],
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iRUKgIgADg4_"
      },
      "outputs": [],
      "source": [
        "#variable w needs to be checked for correct value, stand-in value used\n",
        "class teacher(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_emg, drop_prob=0.25, w=100):\n",
        "        super(teacher, self).__init__()\n",
        "\n",
        "        self.w=w\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "        self.encoder_1_emg=Encoder_1(input_emg, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "        self.encoder_2_emg=Encoder_2(input_emg, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_emg= nn.BatchNorm1d(input_emg, affine=False)\n",
        "\n",
        "\n",
        "        self.fc = nn.Linear(2*3*128+128,3)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "        self.gate_3=GatingModule(128)\n",
        "\n",
        "        self.fc_kd = nn.Linear(3*128, 2*128)\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*3*128+128, 2*3*128+128), nn.Sigmoid())\n",
        "\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_emg):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_emg_1=x_emg.view(x_emg.size(0)*x_emg.size(1),x_emg.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_emg_1=self.BN_emg(x_emg_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, self.w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, self.w, x_gyr_1.size(-1))\n",
        "        x_emg_2=x_emg_1.view(-1, self.w, x_emg_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "        x_emg_1=self.encoder_1_emg(x_emg_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "        x_emg_2=self.encoder_2_emg(x_emg_2)\n",
        "\n",
        "        # x_acc=torch.cat((x_acc_1,x_acc_2),dim=-1)\n",
        "        # x_gyr=torch.cat((x_gyr_1,x_gyr_2),dim=-1)\n",
        "        # x_emg=torch.cat((x_emg_1,x_emg_2),dim=-1)\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "        x_emg=self.gate_3(x_emg_1,x_emg_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_emg),dim=-1)\n",
        "        x_kd=self.fc_kd(x)\n",
        "\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        weights_3 = self.weighted_feat(x[:,:,2*128:3*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        x_3=weights_3*x[:,:,2*128:3*128]\n",
        "        out_3=x_1+x_2+x_3\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        #print(out.shape)\n",
        "        return out,x_kd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "j5TbnYqfKb4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e245cc7-ab49-44b3-fe5a-91f2b65e3318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 20.2796, Training Loss: 0.2645,  Validation loss: 0.1410\n",
            "Epoch: 2, time: 19.6008, Training Loss: 0.2047,  Validation loss: 0.1015\n",
            "Epoch: 3, time: 20.0305, Training Loss: 0.1884,  Validation loss: 0.0984\n",
            "Epoch: 4, time: 20.5234, Training Loss: 0.1777,  Validation loss: 0.0981\n",
            "Epoch: 5, time: 21.0998, Training Loss: 0.1699,  Validation loss: 0.0968\n",
            "Epoch: 6, time: 20.9858, Training Loss: 0.1635,  Validation loss: 0.0932\n",
            "Epoch: 7, time: 20.7143, Training Loss: 0.1586,  Validation loss: 0.0969\n",
            "Epoch: 8, time: 20.7349, Training Loss: 0.1540,  Validation loss: 0.0911\n",
            "Epoch: 9, time: 20.9064, Training Loss: 0.1501,  Validation loss: 0.0921\n",
            "Epoch: 10, time: 20.9250, Training Loss: 0.1479,  Validation loss: 0.0924\n",
            "Epoch: 11, time: 20.9205, Training Loss: 0.1435,  Validation loss: 0.0914\n",
            "Epoch: 12, time: 20.8693, Training Loss: 0.1410,  Validation loss: 0.0914\n",
            "Epoch: 13, time: 20.8417, Training Loss: 0.1391,  Validation loss: 0.0932\n",
            "Epoch: 14, time: 20.8192, Training Loss: 0.1367,  Validation loss: 0.0928\n",
            "Epoch: 15, time: 20.8338, Training Loss: 0.1343,  Validation loss: 0.0946\n",
            "Epoch: 16, time: 20.8525, Training Loss: 0.1318,  Validation loss: 0.0927\n",
            "Epoch: 17, time: 20.8784, Training Loss: 0.1290,  Validation loss: 0.0940\n",
            "Epoch: 18, time: 20.8798, Training Loss: 0.1270,  Validation loss: 0.0969\n",
            "Stopping early after 18 epochs\n",
            "Training time: 372.9794714450836 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = teacher(24,24,8)\n",
        "\n",
        "mm_teacher = train_mm_teacher(device, train_loader, val_loader, lr,40, model, filename ='model_teacher.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kBU4maNYKb4O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "outputId": "3b46901a-d05b-40a6-b21a-d4ebdbde4bb5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for teacher:\n\tsize mismatch for encoder_1_acc.lstm_1.weight_ih_l0: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([512, 21]).\n\tsize mismatch for encoder_1_acc.lstm_1.weight_ih_l0_reverse: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([512, 21]).\n\tsize mismatch for encoder_1_gyr.lstm_1.weight_ih_l0: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([512, 21]).\n\tsize mismatch for encoder_1_gyr.lstm_1.weight_ih_l0_reverse: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([512, 21]).\n\tsize mismatch for encoder_2_acc.lstm_1.weight_ih_l0: copying a param with shape torch.Size([384, 24]) from checkpoint, the shape in current model is torch.Size([384, 21]).\n\tsize mismatch for encoder_2_acc.lstm_1.weight_ih_l0_reverse: copying a param with shape torch.Size([384, 24]) from checkpoint, the shape in current model is torch.Size([384, 21]).\n\tsize mismatch for encoder_2_gyr.lstm_1.weight_ih_l0: copying a param with shape torch.Size([384, 24]) from checkpoint, the shape in current model is torch.Size([384, 21]).\n\tsize mismatch for encoder_2_gyr.lstm_1.weight_ih_l0_reverse: copying a param with shape torch.Size([384, 24]) from checkpoint, the shape in current model is torch.Size([384, 21]).\n\tsize mismatch for BN_acc.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([21]).\n\tsize mismatch for BN_acc.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([21]).\n\tsize mismatch for BN_gyr.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([21]).\n\tsize mismatch for BN_gyr.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([21]).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-df51c09404ea>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmm_teacher\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmm_teacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_teacher.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmm_teacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmm_teacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2189\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2190\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for teacher:\n\tsize mismatch for encoder_1_acc.lstm_1.weight_ih_l0: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([512, 21]).\n\tsize mismatch for encoder_1_acc.lstm_1.weight_ih_l0_reverse: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([512, 21]).\n\tsize mismatch for encoder_1_gyr.lstm_1.weight_ih_l0: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([512, 21]).\n\tsize mismatch for encoder_1_gyr.lstm_1.weight_ih_l0_reverse: copying a param with shape torch.Size([512, 24]) from checkpoint, the shape in current model is torch.Size([512, 21]).\n\tsize mismatch for encoder_2_acc.lstm_1.weight_ih_l0: copying a param with shape torch.Size([384, 24]) from checkpoint, the shape in current model is torch.Size([384, 21]).\n\tsize mismatch for encoder_2_acc.lstm_1.weight_ih_l0_reverse: copying a param with shape torch.Size([384, 24]) from checkpoint, the shape in current model is torch.Size([384, 21]).\n\tsize mismatch for encoder_2_gyr.lstm_1.weight_ih_l0: copying a param with shape torch.Size([384, 24]) from checkpoint, the shape in current model is torch.Size([384, 21]).\n\tsize mismatch for encoder_2_gyr.lstm_1.weight_ih_l0_reverse: copying a param with shape torch.Size([384, 24]) from checkpoint, the shape in current model is torch.Size([384, 21]).\n\tsize mismatch for BN_acc.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([21]).\n\tsize mismatch for BN_acc.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([21]).\n\tsize mismatch for BN_gyr.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([21]).\n\tsize mismatch for BN_gyr.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([21])."
          ]
        }
      ],
      "source": [
        "mm_teacher= teacher(24,24,8)\n",
        "mm_teacher.load_state_dict(torch.load('model_teacher.pth'))\n",
        "mm_teacher.to(device)\n",
        "\n",
        "mm_teacher.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, ( data_acc, data_gyr, target, data_EMG) in enumerate(test_loader):\n",
        "        output,x_1= mm_teacher(data_acc.to(device).float(),data_gyr.to(device).float(),  data_EMG.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data_acc, data_gyr, data_EMG, target, output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "#fix\n",
        "rmse, p, Z_1,Z_2,Z_3=RMSE_prediction(yhat_4,test_target, output_dim=3)\n",
        "#,Z_4,Z_5,Z_6,Z_7\n",
        "\n",
        "ablation_1=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb38ILRtNX4D"
      },
      "source": [
        "# Student Model-- 1 IMU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTmA6QwQNiMn"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVoiiFkFNiM5"
      },
      "outputs": [],
      "source": [
        "def train_mm_student_1(device, train_loader, val_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data_acc, data_gyr, target, data_EMG) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output= model(data_acc[:,:,0:3].to(device).float(),data_gyr[:,:,0:3].to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for  data_acc, data_gyr, target, data_EMG in val_loader:\n",
        "                output= model(data_acc[:,:,0:3].to(device).float(),data_gyr[:,:,0:3].to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBeK43kJNiM6"
      },
      "source": [
        "## Multi-Encoder Student Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOIvneh-NiM6"
      },
      "outputs": [],
      "source": [
        "class Encoder_1(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_1, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder_2(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_2, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f3oMa1rNiM6"
      },
      "outputs": [],
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53BTFKDfNiM7"
      },
      "outputs": [],
      "source": [
        "class student_1(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25, w=100):\n",
        "        super(student_1, self).__init__()\n",
        "        self.w=w\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,3)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, self.w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, self.w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "        # x_acc=torch.cat((x_acc_1,x_acc_2),dim=-1)\n",
        "        # x_gyr=torch.cat((x_gyr_1,x_gyr_2),dim=-1)\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7iB4sFYNiM7"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "model = student_1(3,3)\n",
        "\n",
        "mm_student_1 = train_mm_student_1(device, train_loader, val_loader, lr,40,model,'model_student_1.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQn-RnuTNiM8"
      },
      "outputs": [],
      "source": [
        "mm_student_1= student_1(3,3)\n",
        "mm_student_1.load_state_dict(torch.load('model_student_1.pth'))\n",
        "mm_student_1.to(device)\n",
        "\n",
        "mm_student_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, ( data_acc, data_gyr,  target, data_EMG) in enumerate(test_loader):\n",
        "        output = mm_student_1(data_acc[:,:,0:3].to(device).float(),data_gyr[:,:,0:3].to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data_acc, data_gyr, data_EMG, target, output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "#fix\n",
        "rmse, p, Z_1,Z_2,Z_3=RMSE_prediction(yhat_4,test_target, output_dim=3)\n",
        "\n",
        "ablation_2=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uyvUraYOHCh"
      },
      "source": [
        "## Knowledge+Sensor Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiO2hPE7RtPH"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Knowledge distillation\"\"\"\n",
        "\n",
        "def train_student_1(device, alpha, beta, train_loader, val_loader, learn_rate, EPOCHS, model, filename, teacher):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion_2 =RMSELoss()\n",
        "    # criterion_2 =nn.MSELoss()\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    total_running_loss=0\n",
        "    running_loss=0\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, ( data_acc, data_gyr,  target, data_EMG) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            student_output, x_student_1= model(data_acc[:,:,0:3].to(device).float(),data_gyr[:,:,0:3].to(device).float())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_output,x_teacher_1= teacher(data_acc.to(device).float(),data_gyr.to(device).float(), data_EMG.to(device).float())\n",
        "\n",
        "            loss=criterion_2(student_output,target.to(device))+alpha*criterion_2(student_output,teacher_output)+beta*criterion_2(x_student_1,x_teacher_1)\n",
        "\n",
        "            loss_1=criterion_2(student_output,target.to(device))\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data_acc, data_gyr, target, data_EMG in val_loader:\n",
        "                output,student_1= model(data_acc[:,:,0:3].to(device).float(),data_gyr[:,:,0:3].to(device).float())\n",
        "                val_loss += criterion_2(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJielY927HEj"
      },
      "outputs": [],
      "source": [
        "class student_1_KD(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25, w=100):\n",
        "        super(student_1_KD, self).__init__()\n",
        "        self.w=w\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc_kd=nn.Linear(2*128,2*128)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,3)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, self.w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, self.w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        x_KD=self.fc_kd(x)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x_KD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeZh5DcW6WfE"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "student = student_1_KD(3,3)\n",
        "\n",
        "teacher_trained= teacher(24,24,8)\n",
        "teacher_trained.load_state_dict(torch.load('model_teacher.pth'))\n",
        "teacher_trained.to(device)\n",
        "alpha=0.01\n",
        "beta=0.01\n",
        "\n",
        "student_KD= train_student_1(device, alpha, beta, train_loader, val_loader, lr,40, student, 'student_1_KD.pth', teacher_trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVzh7GCMo_Xp"
      },
      "outputs": [],
      "source": [
        "mm_student_1= student_1_KD(3,3)\n",
        "mm_student_1.load_state_dict(torch.load('student_1_KD.pth'))\n",
        "mm_student_1.to(device)\n",
        "\n",
        "mm_student_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, ( data_acc, data_gyr,  target,data_EMG) in enumerate(test_loader):\n",
        "        output,student_1 = mm_student_1(data_acc[:,:,0:3].to(device).float(),data_gyr[:,:,0:3].to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data_acc, data_gyr, data_EMG, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3=RMSE_prediction(yhat_4,test_target,output_dim=3)\n",
        "\n",
        "ablation_3=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmFKq9UITrlk"
      },
      "source": [
        "# Student Model-- 2 IMUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0m07kPlTrlr"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GD_yaiuTrlr"
      },
      "outputs": [],
      "source": [
        "def train_mm_student_2(device, train_loader, val_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, ( data_acc, data_gyr, target, data_EMG) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data_acc=torch.cat((data_acc[:,:,0:3],data_acc[:,:,9:12]),dim=-1)\n",
        "            data_gyr=torch.cat((data_gyr[:,:,0:3],data_gyr[:,:,9:12]),dim=-1)\n",
        "            output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data_acc, data_gyr, target, data_EMG in val_loader:\n",
        "                data_acc=torch.cat((data_acc[:,:,0:3],data_acc[:,:,9:12]),dim=-1)\n",
        "                data_gyr=torch.cat((data_gyr[:,:,0:3],data_gyr[:,:,9:12]),dim=-1)\n",
        "                output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c5Z_AIpTrls"
      },
      "source": [
        "## Multi-Encoder Student Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBXPRY4cTrls"
      },
      "outputs": [],
      "source": [
        "class Encoder_1(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_1, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder_2(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_2, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqeiHJ9iTrls"
      },
      "outputs": [],
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkGKiPgGTrls"
      },
      "outputs": [],
      "source": [
        "class student_2(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25, w=100):\n",
        "        super(student_2, self).__init__()\n",
        "        self.w=w\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,3)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "        # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, self.w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, self.w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "        # x_acc=torch.cat((x_acc_1,x_acc_2),dim=-1)\n",
        "        # x_gyr=torch.cat((x_gyr_1,x_gyr_2),dim=-1)\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4YwEU5CTrls"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "model = student_2(6,6)\n",
        "\n",
        "mm_student_2 = train_mm_student_2(device, train_loader, val_loader, lr,40,model,'model_student_2.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7dLEwNfTrlt"
      },
      "outputs": [],
      "source": [
        "mm_student_2= student_2(6,6)\n",
        "mm_student_2.load_state_dict(torch.load('model_student_2.pth'))\n",
        "mm_student_2.to(device)\n",
        "\n",
        "mm_student_2.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data_acc, data_gyr, target, data_EMG) in enumerate(test_loader):\n",
        "        data_acc=torch.cat((data_acc[:,:,0:3],data_acc[:,:,9:12]),dim=-1)\n",
        "        data_gyr=torch.cat((data_gyr[:,:,0:3],data_gyr[:,:,9:12]),dim=-1)\n",
        "        output = mm_student_2(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data_acc, data_gyr, target, data_EMG\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3=RMSE_prediction(yhat_4,test_target,output_dim=3)\n",
        "\n",
        "ablation_4=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyY3Mq-cxksP"
      },
      "source": [
        "## Knowledge+Sensor Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WQ7gzNuxksQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Knowledge distillation\"\"\"\n",
        "\n",
        "def train_student_2(device, train_loader, val_loader, learn_rate, EPOCHS, model, filename, teacher):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion_2 =RMSELoss()\n",
        "    # criterion_2 =nn.MSELoss()\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    total_running_loss=0\n",
        "    running_loss=0\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data_acc, data_gyr, target, data_EMG) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data_acc_1=torch.cat((data_acc[:,:,0:3],data_acc[:,:,9:12]),dim=-1)\n",
        "            data_gyr_1=torch.cat((data_gyr[:,:,0:3],data_gyr[:,:,9:12]),dim=-1)\n",
        "            student_output, x_student_1= model(data_acc_1.to(device).float(),data_gyr_1.to(device).float())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_output,x_teacher_1= teacher(data_acc.to(device).float(),data_gyr.to(device).float(), data_EMG.to(device).float())\n",
        "\n",
        "            loss=criterion_2(student_output,target.to(device))+alpha*criterion_2(student_output,teacher_output)+beta*criterion_2(x_student_1,x_teacher_1)\n",
        "\n",
        "            loss_1=criterion_2(student_output,target.to(device))\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data_acc, data_gyr, target, data_EMG in val_loader:\n",
        "                data_acc_1=torch.cat((data_acc[:,:,0:3],data_acc[:,:,9:12]),dim=-1)\n",
        "                data_gyr_1=torch.cat((data_gyr[:,:,0:3],data_gyr[:,:,9:12]),dim=-1)\n",
        "                output,student_1= model(data_acc_1.to(device).float(),data_gyr_1.to(device).float())\n",
        "                val_loss += criterion_2(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qfdVIPuxksR"
      },
      "outputs": [],
      "source": [
        "class student_2_KD(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25, w=100):\n",
        "        super(student_2_KD, self).__init__()\n",
        "        self.w=w\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc_kd=nn.Linear(2*128,2*128)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,3)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, self.w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, self.w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        x_KD=self.fc_kd(x)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x_KD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZgBF_cbxksR"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "student = student_2_KD(6,6)\n",
        "\n",
        "teacher_trained= teacher(24,24,8)\n",
        "teacher_trained.load_state_dict(torch.load('model_teacher.pth'))\n",
        "teacher_trained.to(device)\n",
        "\n",
        "\n",
        "student_KD= train_student_2(device, train_loader, val_loader, lr,40, student, 'student_2_KD.pth', teacher_trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5q0Kd6jxksR"
      },
      "outputs": [],
      "source": [
        "mm_student_1= student_2_KD(6,6)\n",
        "mm_student_1.load_state_dict(torch.load('student_2_KD.pth'))\n",
        "mm_student_1.to(device)\n",
        "\n",
        "mm_student_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data_acc, data_gyr, target, data_EMG) in enumerate(test_loader):\n",
        "        data_acc=torch.cat((data_acc[:,:,0:3],data_acc[:,:,9:12]),dim=-1)\n",
        "        data_gyr=torch.cat((data_gyr[:,:,0:3],data_gyr[:,:,9:12]),dim=-1)\n",
        "        output,student_1 = mm_student_1(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data_acc, data_gyr, target, data_EMG, output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3=RMSE_prediction(yhat_4,test_target,output_dim=3)\n",
        "\n",
        "ablation_5=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-nzXUaqkv6K"
      },
      "source": [
        "# Student Model-- 3 IMUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXQdxO9Tkv6S"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyHRvdqVkv6S"
      },
      "outputs": [],
      "source": [
        "def train_mm_student_3(device, train_loader, val_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data_acc, data_gyr, target, data_EMG) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data_acc=torch.cat((data_acc[:,:,0:6],data_acc[:,:,9:12]),dim=-1)\n",
        "            data_gyr=torch.cat((data_gyr[:,:,0:6],data_gyr[:,:,9:12]),dim=-1)\n",
        "            output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data_acc, data_gyr, target, data_EMG in val_loader:\n",
        "                data_acc=torch.cat((data_acc[:,:,0:6],data_acc[:,:,9:12]),dim=-1)\n",
        "                data_gyr=torch.cat((data_gyr[:,:,0:6],data_gyr[:,:,9:12]),dim=-1)\n",
        "                output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxw_KcPTkv6S"
      },
      "source": [
        "## Multi-Encoder Student Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DZBviIRkv6S"
      },
      "outputs": [],
      "source": [
        "class Encoder_1(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_1, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder_2(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_2, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iVFE3PKkv6S"
      },
      "outputs": [],
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5gcL_U8kv6S"
      },
      "outputs": [],
      "source": [
        "class student_3(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25, w=100):\n",
        "        super(student_3, self).__init__()\n",
        "        self.w=w\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,3)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, self.w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, self.w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "        # x_acc=torch.cat((x_acc_1,x_acc_2),dim=-1)\n",
        "        # x_gyr=torch.cat((x_gyr_1,x_gyr_2),dim=-1)\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBWkb1MVkv6T"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "model = student_3(9,9)\n",
        "\n",
        "mm_student_3 = train_mm_student_3(device, train_loader, val_loader, lr,40,model,'model_student_3.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD76m5u1kv6T"
      },
      "outputs": [],
      "source": [
        "mm_student_3= student_3(9,9)\n",
        "mm_student_3.load_state_dict(torch.load('model_student_3.pth'))\n",
        "mm_student_3.to(device)\n",
        "\n",
        "mm_student_3.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data_acc, data_gyr, target, data_EMG) in enumerate(test_loader):\n",
        "        data_acc=torch.cat((data_acc[:,:,0:6],data_acc[:,:,9:12]),dim=-1)\n",
        "        data_gyr=torch.cat((data_gyr[:,:,0:6],data_gyr[:,:,9:12]),dim=-1)\n",
        "        output = mm_student_3(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data_acc, data_gyr, target, data_EMG\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3=RMSE_prediction(yhat_4,test_target,output_dim=3)\n",
        "\n",
        "ablation_6=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXDErlYz01Ed"
      },
      "source": [
        "## Knowledge+Sensor Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "861u27XN01Ed"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Knowledge distillation\"\"\"\n",
        "\n",
        "def train_student_3(device, train_loader, val_loader, learn_rate, EPOCHS, model, filename, teacher):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion_2 =RMSELoss()\n",
        "    # criterion_2 =nn.MSELoss()\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    total_running_loss=0\n",
        "    running_loss=0\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data_acc, data_gyr, target, data_EMG) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data_acc_1=torch.cat((data_acc[:,:,0:6],data_acc[:,:,9:12]),dim=-1)\n",
        "            data_gyr_1=torch.cat((data_gyr[:,:,0:6],data_gyr[:,:,9:12]),dim=-1)\n",
        "            student_output, x_student_1= model(data_acc_1.to(device).float(),data_gyr_1.to(device).float())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_output,x_teacher_1= teacher(data_acc.to(device).float(),data_gyr.to(device).float(), data_EMG.to(device).float())\n",
        "\n",
        "            loss=criterion_2(student_output,target.to(device))+alpha*criterion_2(student_output,teacher_output)+beta*criterion_2(x_student_1,x_teacher_1)\n",
        "\n",
        "            loss_1=criterion_2(student_output,target.to(device))\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data_acc, data_gyr, target, data_EMG in val_loader:\n",
        "                data_acc_1=torch.cat((data_acc[:,:,0:6],data_acc[:,:,9:12]),dim=-1)\n",
        "                data_gyr_1=torch.cat((data_gyr[:,:,0:6],data_gyr[:,:,9:12]),dim=-1)\n",
        "                output,student_1= model(data_acc_1.to(device).float(),data_gyr_1.to(device).float())\n",
        "                val_loss += criterion_2(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HHg_7ML01Ee"
      },
      "outputs": [],
      "source": [
        "class student_3_KD(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25, w=100):\n",
        "        super(student_3_KD, self).__init__()\n",
        "        self.w=w\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc_kd=nn.Linear(2*128,2*128)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,3)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, self.w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, self.w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        x_KD=self.fc_kd(x)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x_KD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj_jcX4g01Ee"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "student = student_3_KD(9,9)\n",
        "\n",
        "teacher_trained= teacher(24,24,8)\n",
        "teacher_trained.load_state_dict(torch.load('model_teacher.pth'))\n",
        "teacher_trained.to(device)\n",
        "\n",
        "\n",
        "student_KD= train_student_3(device, train_loader, val_loader, lr,40, student, 'student_3_KD.pth', teacher_trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7h_glhS01Ee"
      },
      "outputs": [],
      "source": [
        "mm_student_1= student_3_KD(9,9)\n",
        "mm_student_1.load_state_dict(torch.load('student_3_KD.pth'))\n",
        "mm_student_1.to(device)\n",
        "\n",
        "mm_student_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data_acc, data_gyr, target, data_EMG) in enumerate(test_loader):\n",
        "        data_acc=torch.cat((data_acc[:,:,0:6],data_acc[:,:,9:12]),dim=-1)\n",
        "        data_gyr=torch.cat((data_gyr[:,:,0:6],data_gyr[:,:,9:12]),dim=-1)\n",
        "        output,student_1 = mm_student_1(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data_acc, data_gyr, target, data_EMG, output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3=RMSE_prediction(yhat_4,test_target,output_dim=3)\n",
        "\n",
        "ablation_7=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FCwGDTxnDz4"
      },
      "source": [
        "# Student Model-- 4 IMUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7lJrK8dnDz_"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORd5A3HBnDz_"
      },
      "outputs": [],
      "source": [
        "def train_mm_student_4(device, train_loader, val_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data_acc, data_gyr, target, data_EMG) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data_acc=torch.cat((data_acc[:,:,0:9],data_acc[:,:,9:12]),dim=-1)\n",
        "            data_gyr=torch.cat((data_gyr[:,:,0:9],data_gyr[:,:,9:12]),dim=-1)\n",
        "            output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data_acc, data_gyr, target, data_EMG in val_loader:\n",
        "                data_acc=torch.cat((data_acc[:,:,0:9],data_acc[:,:,9:12]),dim=-1)\n",
        "                data_gyr=torch.cat((data_gyr[:,:,0:9],data_gyr[:,:,9:12]),dim=-1)\n",
        "                output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GqVXImunDz_"
      },
      "source": [
        "## Multi-Encoder Student Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YgQpww1nDz_"
      },
      "outputs": [],
      "source": [
        "class Encoder_1(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_1, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder_2(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_2, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAKQ7MMYnDz_"
      },
      "outputs": [],
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcTyTvHcnDz_"
      },
      "outputs": [],
      "source": [
        "class student_4(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25, w=100):\n",
        "        super(student_4, self).__init__()\n",
        "        self.w=w\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,3)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, self.w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, self.w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "        # x_acc=torch.cat((x_acc_1,x_acc_2),dim=-1)\n",
        "        # x_gyr=torch.cat((x_gyr_1,x_gyr_2),dim=-1)\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzuBnq3WnDz_"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "model = student_4(12,12)\n",
        "\n",
        "mm_student_4 = train_mm_student_4(device, train_loader, val_loader,  lr,40,model, 'model_student_4.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4icckZbqnD0A"
      },
      "outputs": [],
      "source": [
        "mm_student_4= student_4(12,12)\n",
        "mm_student_4.load_state_dict(torch.load('model_student_4.pth'))\n",
        "mm_student_4.to(device)\n",
        "\n",
        "mm_student_4.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data_acc, data_gyr, target, data_EMG) in enumerate(test_loader):\n",
        "        data_acc=torch.cat((data_acc[:,:,0:9],data_acc[:,:,9:12]),dim=-1)\n",
        "        data_gyr=torch.cat((data_gyr[:,:,0:9],data_gyr[:,:,9:12]),dim=-1)\n",
        "        output = mm_student_4(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data_acc, data_gyr, target, data_EMG\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3=RMSE_prediction(yhat_4,test_target,output_dim=3)\n",
        "\n",
        "ablation_8=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZu22Q6e2Mhw"
      },
      "source": [
        "## Knowledge+Sensor Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHS-CXaR2Mhx"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Knowledge distillation\"\"\"\n",
        "\n",
        "def train_student_4(device, train_loader, val_loader, learn_rate, EPOCHS, model, filename, teacher):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion_2 =RMSELoss()\n",
        "    # criterion_2 =nn.MSELoss()\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    total_running_loss=0\n",
        "    running_loss=0\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data_acc, data_gyr, target, data_EMG) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data_acc_1=torch.cat((data_acc[:,:,0:9],data_acc[:,:,9:12]),dim=-1)\n",
        "            data_gyr_1=torch.cat((data_gyr[:,:,0:9],data_gyr[:,:,9:12]),dim=-1)\n",
        "            student_output, x_student_1= model(data_acc_1.to(device).float(),data_gyr_1.to(device).float())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_output,x_teacher_1= teacher(data_acc.to(device).float(),data_gyr.to(device).float(), data_EMG.to(device).float())\n",
        "\n",
        "            loss=criterion_2(student_output,target.to(device))+alpha*criterion_2(student_output,teacher_output)+beta*criterion_2(x_student_1,x_teacher_1)\n",
        "\n",
        "            loss_1=criterion_2(student_output,target.to(device))\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data_acc, data_gyr, target, data_EMG in val_loader:\n",
        "                data_acc_1=torch.cat((data_acc[:,:,0:9],data_acc[:,:,9:12]),dim=-1)\n",
        "                data_gyr_1=torch.cat((data_gyr[:,:,0:9],data_gyr[:,:,9:12]),dim=-1)\n",
        "                output,student_1= model(data_acc_1.to(device).float(),data_gyr_1.to(device).float())\n",
        "                val_loss += criterion_2(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQ_LbzvU2Mhx"
      },
      "outputs": [],
      "source": [
        "class student_4_KD(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25, w=100):\n",
        "        super(student_4_KD, self).__init__()\n",
        "        self.w=w\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc_kd=nn.Linear(2*128,2*128)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,3)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, self.w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, self.w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        x_KD=self.fc_kd(x)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x_KD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq5Aa9Em2Mhx"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "student = student_4_KD(12,12)\n",
        "\n",
        "teacher_trained= teacher(12,12,11)\n",
        "teacher_trained.load_state_dict(torch.load('model_teacher.pth'))\n",
        "teacher_trained.to(device)\n",
        "\n",
        "\n",
        "student_KD= train_student_4(device, train_loader, val_loader, lr,40, student,'student_4_KD.pth', teacher_trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAO_TfIL2Mhy"
      },
      "outputs": [],
      "source": [
        "mm_student_1= student_4_KD(12,12)\n",
        "mm_student_1.load_state_dict(torch.load('student_4_KD.pth'))\n",
        "mm_student_1.to(device)\n",
        "\n",
        "mm_student_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data_acc, data_gyr, target, data_EMG) in enumerate(test_loader):\n",
        "        data_acc=torch.cat((data_acc[:,:,0:9],data_acc[:,:,9:12]),dim=-1)\n",
        "        data_gyr=torch.cat((data_gyr[:,:,0:9],data_gyr[:,:,9:12]),dim=-1)\n",
        "        output,student_1 = mm_student_1(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data_acc, data_gyr, target, data_EMG, output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3=RMSE_prediction(yhat_4,test_target,output_dim=3)\n",
        "\n",
        "ablation_9=np.hstack([rmse,p])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TrXnoV0Js5CO"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
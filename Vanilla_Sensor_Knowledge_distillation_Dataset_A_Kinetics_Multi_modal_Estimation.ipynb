{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevenc15/SD1-project/blob/ML/Vanilla_Sensor_Knowledge_distillation_Dataset_A_Kinetics_Multi_modal_Estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H__KTa0RNQDo",
        "outputId": "a195042e-67b3-43bd-d081-4ff0c6e0b1c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.0.1+cu118)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4130 sha256=48f3a57a3bce6c6625f3d4cbc8d783803ea4b66587c6179bdf8b1ad4df11f0c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install torchviz\n",
        "# !pip install tsf\n",
        "\n",
        "\n",
        "import h5py\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy\n",
        "import statistics\n",
        "from numpy import loadtxt\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statistics import stdev\n",
        "import math\n",
        "import h5py\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from scipy.signal import butter,filtfilt\n",
        "import sys\n",
        "import numpy as np # linear algebra\n",
        "from scipy.stats import randint\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
        "import matplotlib.pyplot as plt # this is used for the plot the graph\n",
        "import seaborn as sns # used for plot interactive graph.\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# from tsf.model import TransformerForecaster\n",
        "\n",
        "\n",
        "# from tensorflow.keras.utils import np_utils\n",
        "import itertools\n",
        "###  Library for attention layers\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "#from tqdm import tqdm # Processing time measurement\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import statistics\n",
        "import gc\n",
        "import torch.nn.init as init\n",
        "\n",
        "############################################################################################################################################################################\n",
        "############################################################################################################################################################################\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.utils.weight_norm as weight_norm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "import gc\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrXnoV0Js5CO"
      },
      "source": [
        "# File path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mq0s3oBqlJ5"
      },
      "source": [
        "# Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP90JbQoR23t"
      },
      "outputs": [],
      "source": [
        "def data_loader(subject):\n",
        "  with h5py.File('/content/drive/My Drive/public dataset/All_subjects_data.h5', 'r') as hf:\n",
        "    All_subjects = hf['All_subjects']\n",
        "    Subject = All_subjects[subject]\n",
        "\n",
        "    treadmill = Subject['Treadmill']\n",
        "    levelground = Subject['Levelground']\n",
        "    ramp = Subject['Ramp']\n",
        "    stair = Subject['Stair']\n",
        "\n",
        "    All_data=np.concatenate((treadmill,levelground,ramp,stair),axis=0)\n",
        "\n",
        "    return np.array(All_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subject_7_data=data_loader('Subject_7')\n",
        "gc.collect()\n",
        "subject_8_data=data_loader('Subject_8')\n",
        "gc.collect()\n",
        "subject_9_data=data_loader('Subject_9')\n",
        "gc.collect()\n",
        "subject_10_data=data_loader('Subject_10')\n",
        "gc.collect()\n",
        "subject_11_data=data_loader('Subject_11')\n",
        "gc.collect()\n",
        "subject_12_data=data_loader('Subject_12')\n",
        "gc.collect()\n",
        "subject_13_data=data_loader('Subject_13')\n",
        "gc.collect()\n",
        "subject_14_data=data_loader('Subject_14')\n",
        "gc.collect()\n",
        "subject_15_data=data_loader('Subject_15')\n",
        "gc.collect()\n",
        "subject_16_data=data_loader('Subject_16')\n",
        "gc.collect()\n",
        "subject_17_data=data_loader('Subject_17')\n",
        "gc.collect()\n",
        "subject_18_data=data_loader('Subject_18')\n",
        "gc.collect()\n",
        "subject_19_data=data_loader('Subject_19')\n",
        "gc.collect()\n",
        "subject_21_data=data_loader('Subject_21')\n",
        "gc.collect()\n",
        "subject_23_data=data_loader('Subject_23')\n",
        "gc.collect()\n",
        "subject_24_data=data_loader('Subject_24')\n",
        "gc.collect()\n",
        "subject_25_data=data_loader('Subject_25')\n",
        "gc.collect()\n",
        "subject_27_data=data_loader('Subject_27')\n",
        "gc.collect()\n",
        "subject_28_data=data_loader('Subject_28')\n",
        "gc.collect()\n",
        "subject_30_data=data_loader('Subject_30')\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "bwAGWjGhIujD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c12b4e4-eeba-4d26-9eaa-c1895bbeeac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "AdB-Um0j39iS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9fb5fd-cd82-4fa0-a78c-4315046c486d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM9iGjQ6uXU-"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fTO4veYsyC7"
      },
      "outputs": [],
      "source": [
        "main_dir = \"/content/drive/My Drive/public dataset/Public_dataset_2/Subject01\"\n",
        "# os.mkdir(main_dir)\n",
        "path=\"/content/\"\n",
        "subject='Subject_01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvt8kQG5iLMP"
      },
      "outputs": [],
      "source": [
        "# train_dataset=np.concatenate((subject_8_data,subject_9_data,subject_10_data,subject_11_data,subject_12_data,subject_13_data,\n",
        "#                               subject_14_data,subject_15_data,subject_16_data,subject_17_data,subject_18_data,subject_19_data,\n",
        "#                               subject_21_data,subject_23_data,subject_24_data,subject_25_data,subject_27_data,subject_28_data,subject_30_data),axis=0)\n",
        "\n",
        "train_dataset=np.concatenate((subject_8_data,subject_9_data,subject_10_data),axis=0)\n",
        "\n",
        "test_dataset=subject_7_data\n",
        "\n",
        "encoder='lstm'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjJR9W7Y9XVA",
        "outputId": "e46d1245-5036-4dbe-fb96-6afa6fa65556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(409645, 129)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7U-luFUh3gy",
        "outputId": "be49e659-d118-412f-824d-3f7a880c03f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(409645, 12)\n",
            "(409645, 7)\n",
            "(409645, 66)\n",
            "[[False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " ...\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]]\n",
            "(850496, 73)\n",
            "1186010\n",
            "(850500, 7)\n",
            "(6804, 100, 59) (6804, 100, 7) (1701, 100, 59) (1701, 100, 7)\n",
            "6804\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Train features #\n",
        "\n",
        "\n",
        "\n",
        "## IMUs-0:24\n",
        "## IK-24:47\n",
        "## ID-47:70\n",
        "## GRF-70:79\n",
        "## GON-79:84\n",
        "## EMG-84:106\n",
        "## JP-106:129\n",
        "\n",
        "\n",
        "x_train_IMUs=train_dataset[:,0:24]\n",
        "x_train_Kinematics=train_dataset[:,24:47]\n",
        "x_train_kinetics=train_dataset[:,47:70]\n",
        "x_train_GRF=train_dataset[:,70:79]\n",
        "x_train_GON=train_dataset[:,79:84]\n",
        "x_train_EMG=train_dataset[:,95:106]\n",
        "x_train_JP=train_dataset[:,106:129]\n",
        "\n",
        "x_train_Kinematics=np.concatenate((x_train_Kinematics[:,6:12],x_train_Kinematics[:,13:19]),axis=1)\n",
        "x_train_JP=np.concatenate((x_train_JP[:,6:9],x_train_JP[:,15:16],x_train_JP[:,17:18],x_train_JP[:,19:20],x_train_JP[:,21:22]),axis=1)\n",
        "\n",
        "x_train_kinetics=np.concatenate((x_train_kinetics[:,6:8],x_train_kinetics[:,15:16],x_train_kinetics[:,17:18]),axis=1)\n",
        "\n",
        "x_train=np.concatenate((x_train_IMUs,x_train_Kinematics,x_train_EMG,x_train_JP,x_train_GON,x_train_kinetics,x_train_GRF[:,0:3]),axis=1)\n",
        "\n",
        "\n",
        "scale= StandardScaler()\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train_X_1_1=x_train\n",
        "\n",
        "# # Test features #\n",
        "x_test_IMUs=test_dataset[:,0:24]\n",
        "x_test_Kinematics=test_dataset[:,24:47]\n",
        "x_test_kinetics=test_dataset[:,47:70]\n",
        "x_test_GRF=test_dataset[:,70:79]\n",
        "x_test_GON=test_dataset[:,79:84]\n",
        "x_test_EMG=test_dataset[:,95:106]\n",
        "x_test_JP=test_dataset[:,106:129]\n",
        "\n",
        "x_test_Kinematics=np.concatenate((x_test_Kinematics[:,6:12],x_test_Kinematics[:,13:19]),axis=1)\n",
        "x_test_JP=np.concatenate((x_test_JP[:,6:9],x_test_JP[:,15:16],x_test_JP[:,17:18],x_test_JP[:,17:18],x_test_JP[:,19:20]),axis=1)\n",
        "\n",
        "print(x_test_Kinematics.shape)\n",
        "print(x_test_JP.shape)\n",
        "\n",
        "x_test_kinetics=np.concatenate((x_test_kinetics[:,6:8],x_test_kinetics[:,15:16],x_test_kinetics[:,17:18]),axis=1)\n",
        "\n",
        "x_test=np.concatenate((x_test_IMUs,x_test_Kinematics,x_test_EMG,x_test_JP,x_test_GON,x_test_kinetics,x_test_GRF[:,0:3]),axis=1)\n",
        "\n",
        "\n",
        "test_X_1_1=x_test\n",
        "\n",
        "print(x_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "m1=59\n",
        "m2=66\n",
        "\n",
        "\n",
        "\n",
        "  ### Label ###\n",
        "\n",
        "train_y_1_1=train_dataset[:,m1:m2]\n",
        "test_y_1_1=test_dataset[:,m1:m2]\n",
        "\n",
        "train_dataset_1=np.concatenate((train_X_1_1,train_y_1_1),axis=1)\n",
        "test_dataset_1=np.concatenate((test_X_1_1,test_y_1_1),axis=1)\n",
        "\n",
        "train_dataset_1=pd.DataFrame(train_dataset_1)\n",
        "test_dataset_1=pd.DataFrame(test_dataset_1)\n",
        "\n",
        "train_dataset_1.dropna(axis=0,inplace=True)\n",
        "test_dataset_1.dropna(axis=0,inplace=True)\n",
        "\n",
        "train_dataset_1=np.array(train_dataset_1)\n",
        "test_dataset_1=np.array(test_dataset_1)\n",
        "\n",
        "train_dataset_sum = np. sum(train_dataset_1)\n",
        "array_has_nan = np. isinf(train_dataset_1[:,0:59])\n",
        "\n",
        "print(array_has_nan)\n",
        "\n",
        "print(train_dataset_1.shape)\n",
        "\n",
        "\n",
        "\n",
        "train_X_1=train_dataset_1[:,0:m1]\n",
        "test_X_1=test_dataset_1[:,0:m1]\n",
        "\n",
        "train_y_1=train_dataset_1[:,m1:m1+7]\n",
        "test_y_1=test_dataset_1[:,m1:m1+7]\n",
        "\n",
        "\n",
        "\n",
        "L1=len(train_X_1)\n",
        "L2=len(test_X_1)\n",
        "\n",
        "print(L1+L2)\n",
        "\n",
        "w=100\n",
        "\n",
        "\n",
        "\n",
        "a1=L1//w\n",
        "b1=L1%w\n",
        "\n",
        "a2=L2//w\n",
        "b2=L2%w\n",
        "\n",
        "# a3=L3//w\n",
        "# b3=L3%w\n",
        "\n",
        "     #### Features ####\n",
        "train_X_2=train_X_1[L1-w+b1:L1,:]\n",
        "test_X_2=test_X_1[L2-w+b2:L2,:]\n",
        "# validation_X_2=validation_X_1[L3-w+b3:L3,:]\n",
        "\n",
        "\n",
        "    #### Output ####\n",
        "\n",
        "train_y_2=train_y_1[L1-w+b1:L1,:]\n",
        "test_y_2=test_y_1[L2-w+b2:L2,:]\n",
        "# validation_y_2=validation_y_1[L3-w+b3:L3,:]\n",
        "\n",
        "\n",
        "\n",
        "     #### Features ####\n",
        "\n",
        "train_X=np.concatenate((train_X_1,train_X_2),axis=0)\n",
        "test_X=np.concatenate((test_X_1,test_X_2),axis=0)\n",
        "# validation_X=np.concatenate((validation_X_1,validation_X_2),axis=0)\n",
        "\n",
        "\n",
        "    #### Output ####\n",
        "\n",
        "train_y=np.concatenate((train_y_1,train_y_2),axis=0)\n",
        "test_y=np.concatenate((test_y_1,test_y_2),axis=0)\n",
        "# validation_y=np.concatenate((validation_y_1,validation_y_2),axis=0)\n",
        "\n",
        "\n",
        "print(train_y.shape)\n",
        "    #### Reshaping ####\n",
        "train_X_3_p= train_X.reshape((a1+1,w,train_X.shape[1]))\n",
        "test_X = test_X.reshape((a2+1,w,test_X.shape[1]))\n",
        "\n",
        "output_dim=7\n",
        "\n",
        "\n",
        "train_y_3_p= train_y.reshape((a1+1,w,output_dim))\n",
        "test_y= test_y.reshape((a2+1,w,output_dim))\n",
        "\n",
        "\n",
        "\n",
        "# train_X_1D=train_X_3\n",
        "test_X_1D=test_X\n",
        "\n",
        "train_X_3=train_X_3_p\n",
        "train_y_3=train_y_3_p\n",
        "# print(train_X_4.shape,train_y_3.shape)\n",
        "\n",
        "\n",
        "train_X_1D, X_validation_1D, train_y_5, Y_validation = train_test_split(train_X_3,train_y_3, test_size=0.20, random_state=True)\n",
        "#train_X_1D, X_validation_1D_ridge, train_y, Y_validation_ridge = train_test_split(train_X_1D_m,train_y_m, test_size=0.10, random_state=True)   [0:2668,:,:]\n",
        "\n",
        "print(train_X_1D.shape,train_y_5.shape,X_validation_1D.shape,Y_validation.shape)\n",
        "\n",
        "\n",
        "\n",
        "Bag_samples=train_X_1D.shape[0]\n",
        "print(Bag_samples)\n",
        "\n",
        "s=test_X_1D.shape[0]*w\n",
        "\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import savetxt\n",
        "\n",
        "savetxt('test_y.csv', test_y_1, delimiter=',')"
      ],
      "metadata": {
        "id": "VV2EuFMRMHtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4C97S-PeeXd"
      },
      "outputs": [],
      "source": [
        "# from numpy import savetxt\n",
        "# savetxt('train_data_check.csv', train_dataset_1[:,48:92], delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjRHNe1ckRoy"
      },
      "outputs": [],
      "source": [
        "### IMUs- Chest, Waist, Right Foot, Right shank, Right thigh, Left Foot, Left shank, Left thigh, 2D-body coordinate\n",
        "### 0:48- IMU, 48:92-2D body coordinate, 92:97-- Target\n",
        "\n",
        "\n",
        "### Data Processing\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "val_targets = torch.Tensor(Y_validation)\n",
        "test_features = torch.Tensor(test_X_1D)\n",
        "test_targets = torch.Tensor(test_y)\n",
        "\n",
        "\n",
        "## all Modality Features\n",
        "\n",
        "train_features = torch.Tensor(train_X_1D)\n",
        "train_targets = torch.Tensor(train_y_5)\n",
        "val_features = torch.Tensor(X_validation_1D)\n",
        "\n",
        "\n",
        "train_features_acc_4=torch.cat((train_features[:,:,0:3],train_features[:,:,6:9],train_features[:,:,12:15],train_features[:,:,18:21]),axis=-1)\n",
        "test_features_acc_4=torch.cat((test_features[:,:,0:3],test_features[:,:,6:9],test_features[:,:,12:15],test_features[:,:,18:21]),axis=-1)\n",
        "val_features_acc_4=torch.cat((val_features[:,:,0:3],val_features[:,:,6:9],val_features[:,:,12:15],val_features[:,:,18:21]),axis=-1)\n",
        "\n",
        "\n",
        "train_features_gyr_4=torch.cat((train_features[:,:,3:6],train_features[:,:,9:12],train_features[:,:,15:18],train_features[:,:,21:24]),axis=-1)\n",
        "test_features_gyr_4=torch.cat((test_features[:,:,3:6],test_features[:,:,9:12],test_features[:,:,15:18],test_features[:,:,21:24]),axis=-1)\n",
        "val_features_gyr_4=torch.cat((val_features[:,:,3:6],val_features[:,:,9:12],val_features[:,:,15:18],val_features[:,:,21:24]),axis=-1)\n",
        "\n",
        "\n",
        "\n",
        "train_features_Kinematics=train_features[:,:,24:36]\n",
        "test_features_Kinematics=test_features[:,:,24:36]\n",
        "val_features_Kinematics=val_features[:,:,24:36]\n",
        "\n",
        "\n",
        "train_features_EMG=train_features[:,:,36:47]\n",
        "test_features_EMG=test_features[:,:,36:47]\n",
        "val_features_EMG=val_features[:,:,36:47]\n",
        "\n",
        "\n",
        "train_features_JP=train_features[:,:,52:59]\n",
        "test_features_JP=test_features[:,:,52:59]\n",
        "val_features_JP=val_features[:,:,52:59]\n",
        "\n",
        "\n",
        "\n",
        "train = TensorDataset(train_features, train_features_acc_4,train_features_gyr_4, train_features_Kinematics,train_features_EMG,train_features_JP, train_targets)\n",
        "val = TensorDataset(val_features, val_features_acc_4, val_features_gyr_4, val_features_Kinematics, val_features_EMG, val_features_JP,val_targets)\n",
        "test = TensorDataset(test_features, test_features_acc_4, test_features_gyr_4, test_features_Kinematics,test_features_EMG,test_features_JP, test_targets)\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=False) # changed shuffled to false\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP_eDnJwrKCC"
      },
      "source": [
        "# Important Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdVunLKprSkv"
      },
      "outputs": [],
      "source": [
        "def RMSE_prediction(yhat_4,test_y,s):\n",
        "\n",
        "  s1=yhat_4.shape[0]*yhat_4.shape[1]\n",
        "\n",
        "  test_o=test_y.reshape((s1,output_dim))\n",
        "  yhat=yhat_4.reshape((s1,output_dim))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  y_1_no=yhat[:,0]\n",
        "  y_2_no=yhat[:,1]\n",
        "  y_3_no=yhat[:,2]\n",
        "  y_4_no=yhat[:,3]\n",
        "  y_5_no=yhat[:,4]\n",
        "  y_6_no=yhat[:,5]\n",
        "  y_7_no=yhat[:,6]\n",
        "  #y_8_no=yhat[:,7]\n",
        "  #y_9_no=yhat[:,8]\n",
        "  #y_10_no=yhat[:,9]\n",
        "\n",
        "\n",
        "  y_1=y_1_no\n",
        "  y_2=y_2_no\n",
        "  y_3=y_3_no\n",
        "  y_4=y_4_no\n",
        "  y_5=y_5_no\n",
        "  y_6=y_6_no\n",
        "  y_7=y_7_no\n",
        "\n",
        "\n",
        "\n",
        "  y_test_1=test_o[:,0]\n",
        "  y_test_2=test_o[:,1]\n",
        "  y_test_3=test_o[:,2]\n",
        "  y_test_4=test_o[:,3]\n",
        "  y_test_5=test_o[:,4]\n",
        "  y_test_6=test_o[:,5]\n",
        "  y_test_7=test_o[:,6]\n",
        "  #y_test_8=test_o[:,7]\n",
        "  #y_test_9=test_o[:,8]\n",
        "  #y_test_10=test_o[:,9]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #print(y_1.shape,y_test_1.shape)\n",
        "\n",
        "\n",
        "\n",
        "  cutoff=6\n",
        "  fs=200\n",
        "  order=4\n",
        "\n",
        "  nyq = 0.5 * fs\n",
        "  ## filtering data ##\n",
        "  def butter_lowpass_filter(data, cutoff, fs, order):\n",
        "      normal_cutoff = cutoff / nyq\n",
        "      # Get the filter coefficients\n",
        "      b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "      y = filtfilt(b, a, data)\n",
        "      return y\n",
        "\n",
        "\n",
        "\n",
        "  # y_1=butter_lowpass_filter(y_1_no, cutoff, fs, order)\n",
        "  # y_2=butter_lowpass_filter(y_2_no, cutoff, fs, order)\n",
        "  # y_3=butter_lowpass_filter(y_3_no, cutoff, fs, order)\n",
        "  # y_4=butter_lowpass_filter(y_4_no, cutoff, fs, order)\n",
        "  # y_5=butter_lowpass_filter(y_5_no, cutoff, fs, order)\n",
        "  # y_6=butter_lowpass_filter(y_6_no, cutoff, fs, order)\n",
        "  # y_7=butter_lowpass_filter(y_7_no, cutoff, fs, order)\n",
        "  #y_8=butter_lowpass_filter(y_8_no, cutoff, fs, order)\n",
        "  #y_9=butter_lowpass_filter(y_9_no, cutoff, fs, order)\n",
        "  #y_10=butter_lowpass_filter(y_10_no, cutoff, fs, order)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  Z_1=y_1\n",
        "  Z_2=y_2\n",
        "  Z_3=y_3\n",
        "  Z_4=y_4\n",
        "  Z_5=y_5\n",
        "  Z_6=y_6\n",
        "  Z_7=y_7\n",
        "  #Z_8=y_8\n",
        "  #Z_9=y_9\n",
        "  #Z_10=y_10\n",
        "\n",
        "\n",
        "\n",
        "  ###calculate RMSE\n",
        "\n",
        "  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1)))/(max(y_test_1)-min(y_test_1)))*100\n",
        "  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2)))/(max(y_test_2)-min(y_test_2)))*100\n",
        "  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3)))/(max(y_test_3)-min(y_test_3)))*100\n",
        "  rmse_4 =((np.sqrt(mean_squared_error(y_test_4,y_4)))/(max(y_test_4)-min(y_test_4)))*100\n",
        "  rmse_5 =((np.sqrt(mean_squared_error(y_test_5,y_5)))/(max(y_test_5)-min(y_test_5)))*100\n",
        "  rmse_6 =((np.sqrt(mean_squared_error(y_test_6,y_6)))/(max(y_test_6)-min(y_test_6)))*100\n",
        "  rmse_7 =((np.sqrt(mean_squared_error(y_test_7,y_7)))/(max(y_test_7)-min(y_test_7)))*100\n",
        "  #rmse_8 =((np.sqrt(mean_squared_error(y_test_8,y_8)))/(max(y_test_8)-min(y_test_8)))*100\n",
        "  #rmse_9 =((np.sqrt(mean_squared_error(y_test_9,y_9)))/(max(y_test_9)-min(y_test_9)))*100\n",
        "  #rmse_10 =((np.sqrt(mean_squared_error(y_test_10,y_10)))/(max(y_test_10)-min(y_test_10)))*100\n",
        "\n",
        "\n",
        "  print(rmse_1)\n",
        "  print(rmse_2)\n",
        "  print(rmse_3)\n",
        "  print(rmse_4)\n",
        "  print(rmse_5)\n",
        "  print(rmse_6)\n",
        "  print(rmse_7)\n",
        "  #print(rmse_8)\n",
        "  #print(rmse_9)\n",
        "  #print(rmse_10)\n",
        "\n",
        "\n",
        "  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n",
        "  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n",
        "  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n",
        "  p_4=np.corrcoef(y_4, y_test_4)[0, 1]\n",
        "  p_5=np.corrcoef(y_5, y_test_5)[0, 1]\n",
        "  p_6=np.corrcoef(y_6, y_test_6)[0, 1]\n",
        "  p_7=np.corrcoef(y_7, y_test_7)[0, 1]\n",
        "  #p_8=np.corrcoef(y_8, y_test_8)[0, 1]\n",
        "  #p_9=np.corrcoef(y_9, y_test_9)[0, 1]\n",
        "  #p_10=np.corrcoef(y_10, y_test_10)[0, 1]\n",
        "\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(p_1)\n",
        "  print(p_2)\n",
        "  print(p_3)\n",
        "  print(p_4)\n",
        "  print(p_5)\n",
        "  print(p_6)\n",
        "  print(p_7)\n",
        "  #print(p_8)\n",
        "  #print(p_9)\n",
        "  #print(p_10)\n",
        "\n",
        "\n",
        "              ### Correlation ###\n",
        "  p=np.array([p_1,p_2,p_3,p_4,p_5,p_6,p_7])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "\n",
        "  rmse=np.array([rmse_1,rmse_2,rmse_3,rmse_4,rmse_5,rmse_6,rmse_7])\n",
        "\n",
        "      #### Mean and standard deviation ####\n",
        "  m=statistics.mean(rmse)\n",
        "  SD=statistics.stdev(rmse)\n",
        "  print('Mean: %.3f' % m,'+/- %.3f' %SD)\n",
        "\n",
        "  m_c=statistics.mean(p)\n",
        "  SD_c=statistics.stdev(p)\n",
        "  print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n",
        "\n",
        "\n",
        "\n",
        "  return rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5,Z_6,Z_7\n",
        "\n",
        "\n",
        "\n",
        "############################################################################################################################################################################################################################################################################################################################################################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        mse = nn.MSELoss()(pred, target)\n",
        "        rmse = torch.sqrt(mse)\n",
        "        return rmse"
      ],
      "metadata": {
        "id": "YhQKyL6ph4hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5Q-cJ2tK8Vb"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgJxMSflV52e"
      },
      "source": [
        "# Teacher Model Training -- IMU-EMG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FG-HuNBV52f"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0iJJkktV52f"
      },
      "outputs": [],
      "source": [
        "def train_mm_teacher(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output,x_1= model(data_acc.to(device).float(),data_gyr.to(device).float(),data_EMG.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_Kinematics, data_EMG,data_JP, target in val_loader:\n",
        "                output,x_1= model(data_acc.to(device).float(),data_gyr.to(device).float(),  data_EMG.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Encoder Teacher Training"
      ],
      "metadata": {
        "id": "endRpZEuDUdp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0bdibsD_Ld2"
      },
      "outputs": [],
      "source": [
        "class Encoder_1(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_1, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder_2(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_2, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ],
      "metadata": {
        "id": "CYWS2knQJnoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRUKgIgADg4_"
      },
      "outputs": [],
      "source": [
        "class teacher(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, input_emg, drop_prob=0.25):\n",
        "        super(teacher, self).__init__()\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "        self.encoder_1_emg=Encoder_1(input_emg, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "        self.encoder_2_emg=Encoder_2(input_emg, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "        self.BN_emg= nn.BatchNorm1d(input_emg, affine=False)\n",
        "\n",
        "\n",
        "        self.fc = nn.Linear(2*3*128+128,7)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "        self.gate_3=GatingModule(128)\n",
        "\n",
        "        self.fc_kd = nn.Linear(3*128, 2*128)\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*3*128+128, 2*3*128+128), nn.Sigmoid())\n",
        "\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr, x_emg):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "        x_emg_1=x_emg.view(x_emg.size(0)*x_emg.size(1),x_emg.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "        x_emg_1=self.BN_emg(x_emg_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, w, x_gyr_1.size(-1))\n",
        "        x_emg_2=x_emg_1.view(-1, w, x_emg_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "        x_emg_1=self.encoder_1_emg(x_emg_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "        x_emg_2=self.encoder_2_emg(x_emg_2)\n",
        "\n",
        "        # x_acc=torch.cat((x_acc_1,x_acc_2),dim=-1)\n",
        "        # x_gyr=torch.cat((x_gyr_1,x_gyr_2),dim=-1)\n",
        "        # x_emg=torch.cat((x_emg_1,x_emg_2),dim=-1)\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "        x_emg=self.gate_3(x_emg_1,x_emg_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr,x_emg),dim=-1)\n",
        "        x_kd=self.fc_kd(x)\n",
        "\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        weights_3 = self.weighted_feat(x[:,:,2*128:3*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        x_3=weights_3*x[:,:,2*128:3*128]\n",
        "        out_3=x_1+x_2+x_3\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x_kd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5TbnYqfKb4I",
        "outputId": "c30a007a-f7c7-46b3-893b-7156f352b328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 8.8468, Training Loss: 0.0754,  Validation loss: 0.0472\n",
            "Epoch: 2, time: 7.5795, Training Loss: 0.0401,  Validation loss: 0.0344\n",
            "Epoch: 3, time: 7.6079, Training Loss: 0.0336,  Validation loss: 0.0294\n",
            "Epoch: 4, time: 7.6767, Training Loss: 0.0300,  Validation loss: 0.0255\n",
            "Epoch: 5, time: 7.7101, Training Loss: 0.0272,  Validation loss: 0.0260\n",
            "Epoch: 6, time: 7.7801, Training Loss: 0.0268,  Validation loss: 0.0246\n",
            "Epoch: 7, time: 7.7666, Training Loss: 0.0251,  Validation loss: 0.0223\n",
            "Epoch: 8, time: 7.8135, Training Loss: 0.0229,  Validation loss: 0.0228\n",
            "Epoch: 9, time: 7.8297, Training Loss: 0.0226,  Validation loss: 0.0217\n",
            "Epoch: 10, time: 7.8648, Training Loss: 0.0209,  Validation loss: 0.0223\n",
            "Epoch: 11, time: 7.8997, Training Loss: 0.0203,  Validation loss: 0.0200\n",
            "Epoch: 12, time: 8.0358, Training Loss: 0.0204,  Validation loss: 0.0206\n",
            "Epoch: 13, time: 7.9736, Training Loss: 0.0196,  Validation loss: 0.0188\n",
            "Epoch: 14, time: 8.0027, Training Loss: 0.0195,  Validation loss: 0.0214\n",
            "Epoch: 15, time: 8.0087, Training Loss: 0.0183,  Validation loss: 0.0191\n",
            "Epoch: 16, time: 8.0394, Training Loss: 0.0175,  Validation loss: 0.0185\n",
            "Epoch: 17, time: 8.0663, Training Loss: 0.0168,  Validation loss: 0.0188\n",
            "Epoch: 18, time: 8.0992, Training Loss: 0.0176,  Validation loss: 0.0198\n",
            "Epoch: 19, time: 8.1228, Training Loss: 0.0176,  Validation loss: 0.0195\n",
            "Epoch: 20, time: 8.1497, Training Loss: 0.0163,  Validation loss: 0.0171\n",
            "Epoch: 21, time: 8.1827, Training Loss: 0.0160,  Validation loss: 0.0176\n",
            "Epoch: 22, time: 8.1898, Training Loss: 0.0158,  Validation loss: 0.0179\n",
            "Epoch: 23, time: 8.2107, Training Loss: 0.0156,  Validation loss: 0.0174\n",
            "Epoch: 24, time: 8.3321, Training Loss: 0.0157,  Validation loss: 0.0186\n",
            "Epoch: 25, time: 8.2360, Training Loss: 0.0151,  Validation loss: 0.0166\n",
            "Epoch: 26, time: 8.2659, Training Loss: 0.0148,  Validation loss: 0.0164\n",
            "Epoch: 27, time: 8.2739, Training Loss: 0.0143,  Validation loss: 0.0163\n",
            "Epoch: 28, time: 8.2931, Training Loss: 0.0141,  Validation loss: 0.0162\n",
            "Epoch: 29, time: 8.2739, Training Loss: 0.0141,  Validation loss: 0.0158\n",
            "Epoch: 30, time: 8.3633, Training Loss: 0.0137,  Validation loss: 0.0163\n",
            "Epoch: 31, time: 8.3339, Training Loss: 0.0137,  Validation loss: 0.0162\n",
            "Epoch: 32, time: 8.3235, Training Loss: 0.0132,  Validation loss: 0.0161\n",
            "Epoch: 33, time: 8.3279, Training Loss: 0.0129,  Validation loss: 0.0161\n",
            "Epoch: 34, time: 8.3282, Training Loss: 0.0128,  Validation loss: 0.0162\n",
            "Epoch: 35, time: 8.3150, Training Loss: 0.0128,  Validation loss: 0.0160\n",
            "Epoch: 36, time: 8.3120, Training Loss: 0.0129,  Validation loss: 0.0167\n",
            "Epoch: 37, time: 8.4177, Training Loss: 0.0136,  Validation loss: 0.0173\n",
            "Epoch: 38, time: 8.3102, Training Loss: 0.0133,  Validation loss: 0.0166\n",
            "Epoch: 39, time: 8.3126, Training Loss: 0.0130,  Validation loss: 0.0161\n",
            "Stopping early after 39 epochs\n",
            "Training time: 317.00522446632385 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = teacher(12,12,11)\n",
        "\n",
        "mm_teacher = train_mm_teacher(train_loader, lr,40,model,path+'_teacher.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBU4maNYKb4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15997198-293f-42d6-83eb-01b09528325a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3420, 100, 7)\n",
            "6.5887026488780975\n",
            "9.242215752601624\n",
            "5.888879299163818\n",
            "5.207854136824608\n",
            "3.7636540830135345\n",
            "7.754693180322647\n",
            "4.52507883310318\n",
            "\n",
            "\n",
            "0.921676394360467\n",
            "0.9051427772133157\n",
            "0.8761357750857902\n",
            "0.9261238136305668\n",
            "0.8536445304192644\n",
            "0.9674884012766992\n",
            "0.9474549533126525\n",
            "Mean: 6.139 +/- 1.898\n",
            "Mean: 0.914 +/- 0.039\n"
          ]
        }
      ],
      "source": [
        "mm_teacher= teacher(12,12,11)\n",
        "mm_teacher.load_state_dict(torch.load(path+'_teacher.pth'))\n",
        "mm_teacher.to(device)\n",
        "\n",
        "mm_teacher.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(test_loader):\n",
        "        output,x_1= mm_teacher(data_acc.to(device).float(),data_gyr.to(device).float(),  data_EMG.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5,Z_6,Z_7=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_1=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student Model-- 1. Foot"
      ],
      "metadata": {
        "id": "Tb38ILRtNX4D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTmA6QwQNiMn"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVoiiFkFNiM5"
      },
      "outputs": [],
      "source": [
        "def train_mm_student_1(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output= model(data_acc[:,:,0:3].to(device).float(),data_gyr[:,:,0:3].to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_Kinematics, data_EMG,data_JP, target in val_loader:\n",
        "                output= model(data_acc[:,:,0:3].to(device).float(),data_gyr[:,:,0:3].to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Encoder Student Training"
      ],
      "metadata": {
        "id": "qBeK43kJNiM6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOIvneh-NiM6"
      },
      "outputs": [],
      "source": [
        "class Encoder_1(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_1, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder_2(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_2, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ],
      "metadata": {
        "id": "7f3oMa1rNiM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53BTFKDfNiM7"
      },
      "outputs": [],
      "source": [
        "class student_1(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25):\n",
        "        super(student_1, self).__init__()\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,7)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "        # x_acc=torch.cat((x_acc_1,x_acc_2),dim=-1)\n",
        "        # x_gyr=torch.cat((x_gyr_1,x_gyr_2),dim=-1)\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7iB4sFYNiM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74082a20-b1f8-4f94-b555-ee9b628de6ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 5.1288, Training Loss: 0.1092,  Validation loss: 0.0839\n",
            "Epoch: 2, time: 5.0684, Training Loss: 0.0784,  Validation loss: 0.0710\n",
            "Epoch: 3, time: 5.0663, Training Loss: 0.0713,  Validation loss: 0.0646\n",
            "Epoch: 4, time: 5.0889, Training Loss: 0.0682,  Validation loss: 0.0646\n",
            "Epoch: 5, time: 5.1004, Training Loss: 0.0650,  Validation loss: 0.0627\n",
            "Epoch: 6, time: 5.1012, Training Loss: 0.0640,  Validation loss: 0.0595\n",
            "Epoch: 7, time: 5.1382, Training Loss: 0.0610,  Validation loss: 0.0587\n",
            "Epoch: 8, time: 5.1787, Training Loss: 0.0600,  Validation loss: 0.0570\n",
            "Epoch: 9, time: 5.1721, Training Loss: 0.0579,  Validation loss: 0.0554\n",
            "Epoch: 10, time: 5.1747, Training Loss: 0.0578,  Validation loss: 0.0544\n",
            "Epoch: 11, time: 5.1731, Training Loss: 0.0563,  Validation loss: 0.0541\n",
            "Epoch: 12, time: 5.1733, Training Loss: 0.0556,  Validation loss: 0.0539\n",
            "Epoch: 13, time: 5.1815, Training Loss: 0.0551,  Validation loss: 0.0535\n",
            "Epoch: 14, time: 5.1943, Training Loss: 0.0547,  Validation loss: 0.0532\n",
            "Epoch: 15, time: 5.2024, Training Loss: 0.0528,  Validation loss: 0.0521\n",
            "Epoch: 16, time: 5.2164, Training Loss: 0.0524,  Validation loss: 0.0519\n",
            "Epoch: 17, time: 5.2100, Training Loss: 0.0511,  Validation loss: 0.0514\n",
            "Epoch: 18, time: 5.2524, Training Loss: 0.0509,  Validation loss: 0.0537\n",
            "Epoch: 19, time: 5.2360, Training Loss: 0.0503,  Validation loss: 0.0511\n",
            "Epoch: 20, time: 5.2720, Training Loss: 0.0488,  Validation loss: 0.0495\n",
            "Epoch: 21, time: 5.2709, Training Loss: 0.0477,  Validation loss: 0.0492\n",
            "Epoch: 22, time: 5.2781, Training Loss: 0.0463,  Validation loss: 0.0481\n",
            "Epoch: 23, time: 5.2820, Training Loss: 0.0461,  Validation loss: 0.0489\n",
            "Epoch: 24, time: 5.2645, Training Loss: 0.0450,  Validation loss: 0.0492\n",
            "Epoch: 25, time: 5.2853, Training Loss: 0.0455,  Validation loss: 0.0487\n",
            "Epoch: 26, time: 5.2793, Training Loss: 0.0440,  Validation loss: 0.0482\n",
            "Epoch: 27, time: 5.2570, Training Loss: 0.0423,  Validation loss: 0.0476\n",
            "Epoch: 28, time: 5.2712, Training Loss: 0.0418,  Validation loss: 0.0476\n",
            "Epoch: 29, time: 5.2641, Training Loss: 0.0420,  Validation loss: 0.0475\n",
            "Epoch: 30, time: 5.2544, Training Loss: 0.0405,  Validation loss: 0.0462\n",
            "Epoch: 31, time: 5.2721, Training Loss: 0.0395,  Validation loss: 0.0472\n",
            "Epoch: 32, time: 5.2412, Training Loss: 0.0386,  Validation loss: 0.0465\n",
            "Epoch: 33, time: 5.2572, Training Loss: 0.0390,  Validation loss: 0.0469\n",
            "Epoch: 34, time: 5.2789, Training Loss: 0.0391,  Validation loss: 0.0487\n",
            "Epoch: 35, time: 5.2443, Training Loss: 0.0397,  Validation loss: 0.0471\n",
            "Epoch: 36, time: 5.2394, Training Loss: 0.0379,  Validation loss: 0.0466\n",
            "Epoch: 37, time: 5.2605, Training Loss: 0.0370,  Validation loss: 0.0473\n",
            "Epoch: 38, time: 5.2472, Training Loss: 0.0363,  Validation loss: 0.0466\n",
            "Epoch: 39, time: 5.2416, Training Loss: 0.0370,  Validation loss: 0.0507\n",
            "Epoch: 40, time: 5.2388, Training Loss: 0.0364,  Validation loss: 0.0454\n",
            "Training time: 209.068598985672 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = student_1(3,3)\n",
        "\n",
        "mm_student_1 = train_mm_student_1(train_loader, lr,40,model,path+'_student_1.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQn-RnuTNiM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8dd4c2-a5df-466d-f19e-fe6421e87fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3420, 100, 7)\n",
            "8.224944770336151\n",
            "13.148409128189087\n",
            "6.892719864845276\n",
            "5.33481240272522\n",
            "3.741455078125\n",
            "8.278337866067886\n",
            "4.377913475036621\n",
            "\n",
            "\n",
            "0.8953363867576765\n",
            "0.8838330072538257\n",
            "0.7864936082430724\n",
            "0.9215454304876781\n",
            "0.8440984346792889\n",
            "0.9640435855059363\n",
            "0.9409150996402469\n",
            "Mean: 7.143 +/- 3.190\n",
            "Mean: 0.891 +/- 0.060\n"
          ]
        }
      ],
      "source": [
        "mm_student_1= student_1(3,3)\n",
        "mm_student_1.load_state_dict(torch.load(path+'_student_1.pth'))\n",
        "mm_student_1.to(device)\n",
        "\n",
        "mm_student_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(test_loader):\n",
        "        output = mm_student_1(data_acc[:,:,0:3].to(device).float(),data_gyr[:,:,0:3].to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5,Z_6,Z_7=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_2=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge+Sensor Distillation"
      ],
      "metadata": {
        "id": "0uyvUraYOHCh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiO2hPE7RtPH"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Knowledge distillation\"\"\"\n",
        "\n",
        "def train_student_1(train_loader, learn_rate, EPOCHS, model, filename, teacher):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion_2 =RMSELoss()\n",
        "    # criterion_2 =nn.MSELoss()\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    total_running_loss=0\n",
        "    running_loss=0\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            student_output, x_student_1= model(data_acc[:,:,0:3].to(device).float(),data_gyr[:,:,0:3].to(device).float())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_output,x_teacher_1= teacher(data_acc.to(device).float(),data_gyr.to(device).float(), data_EMG.to(device).float())\n",
        "\n",
        "            loss=criterion_2(student_output,target.to(device))+alpha*criterion_2(student_output,teacher_output)+beta*criterion_2(x_student_1,x_teacher_1)\n",
        "\n",
        "            loss_1=criterion_2(student_output,target.to(device))\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_Kinematics, data_EMG,data_JP, target in val_loader:\n",
        "                output,student_1= model(data_acc[:,:,0:3].to(device).float(),data_gyr[:,:,0:3].to(device).float())\n",
        "                val_loss += criterion_2(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class student_1_KD(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25):\n",
        "        super(student_1_KD, self).__init__()\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc_kd=nn.Linear(2*128,2*128)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,7)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        x_KD=self.fc_kd(x)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x_KD"
      ],
      "metadata": {
        "id": "EJielY927HEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "student = student_1_KD(3,3)\n",
        "\n",
        "teacher_trained= teacher(12,12,11)\n",
        "teacher_trained.load_state_dict(torch.load(path+'_teacher.pth'))\n",
        "teacher_trained.to(device)\n",
        "\n",
        "\n",
        "student_KD= train_student_1(train_loader, lr,40, student,path+'student_1_KD.pth', teacher_trained)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd3f7ac6-acf5-4088-a7e0-88ee63cec7ac",
        "id": "VeZh5DcW6WfE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 8.0931, Training Loss: 0.1107,  Validation loss: 0.0753\n",
            "Epoch: 2, time: 8.0852, Training Loss: 0.0771,  Validation loss: 0.0695\n",
            "Epoch: 3, time: 8.1071, Training Loss: 0.0706,  Validation loss: 0.0649\n",
            "Epoch: 4, time: 8.1020, Training Loss: 0.0673,  Validation loss: 0.0643\n",
            "Epoch: 5, time: 8.1058, Training Loss: 0.0642,  Validation loss: 0.0609\n",
            "Epoch: 6, time: 8.1043, Training Loss: 0.0625,  Validation loss: 0.0601\n",
            "Epoch: 7, time: 8.1231, Training Loss: 0.0607,  Validation loss: 0.0569\n",
            "Epoch: 8, time: 8.1160, Training Loss: 0.0587,  Validation loss: 0.0572\n",
            "Epoch: 9, time: 8.1078, Training Loss: 0.0574,  Validation loss: 0.0575\n",
            "Epoch: 10, time: 8.1330, Training Loss: 0.0568,  Validation loss: 0.0535\n",
            "Epoch: 11, time: 8.0992, Training Loss: 0.0556,  Validation loss: 0.0538\n",
            "Epoch: 12, time: 8.1099, Training Loss: 0.0538,  Validation loss: 0.0510\n",
            "Epoch: 13, time: 8.1108, Training Loss: 0.0530,  Validation loss: 0.0525\n",
            "Epoch: 14, time: 8.1062, Training Loss: 0.0525,  Validation loss: 0.0512\n",
            "Epoch: 15, time: 8.1160, Training Loss: 0.0511,  Validation loss: 0.0521\n",
            "Epoch: 16, time: 8.1166, Training Loss: 0.0503,  Validation loss: 0.0499\n",
            "Epoch: 17, time: 8.1181, Training Loss: 0.0492,  Validation loss: 0.0492\n",
            "Epoch: 18, time: 8.1033, Training Loss: 0.0493,  Validation loss: 0.0517\n",
            "Epoch: 19, time: 8.1258, Training Loss: 0.0475,  Validation loss: 0.0492\n",
            "Epoch: 20, time: 8.1086, Training Loss: 0.0468,  Validation loss: 0.0478\n",
            "Epoch: 21, time: 8.1082, Training Loss: 0.0458,  Validation loss: 0.0475\n",
            "Epoch: 22, time: 8.1252, Training Loss: 0.0445,  Validation loss: 0.0471\n",
            "Epoch: 23, time: 8.1164, Training Loss: 0.0431,  Validation loss: 0.0480\n",
            "Epoch: 24, time: 8.1102, Training Loss: 0.0429,  Validation loss: 0.0502\n",
            "Epoch: 25, time: 8.1290, Training Loss: 0.0427,  Validation loss: 0.0468\n",
            "Epoch: 26, time: 8.1128, Training Loss: 0.0417,  Validation loss: 0.0483\n",
            "Epoch: 27, time: 8.1020, Training Loss: 0.0407,  Validation loss: 0.0460\n",
            "Epoch: 28, time: 8.0836, Training Loss: 0.0404,  Validation loss: 0.0474\n",
            "Epoch: 29, time: 8.0997, Training Loss: 0.0403,  Validation loss: 0.0471\n",
            "Epoch: 30, time: 8.0910, Training Loss: 0.0395,  Validation loss: 0.0456\n",
            "Epoch: 31, time: 8.0851, Training Loss: 0.0391,  Validation loss: 0.0460\n",
            "Epoch: 32, time: 8.1035, Training Loss: 0.0383,  Validation loss: 0.0472\n",
            "Epoch: 33, time: 8.1053, Training Loss: 0.0385,  Validation loss: 0.0481\n",
            "Epoch: 34, time: 8.0977, Training Loss: 0.0369,  Validation loss: 0.0450\n",
            "Epoch: 35, time: 8.0889, Training Loss: 0.0362,  Validation loss: 0.0459\n",
            "Epoch: 36, time: 8.1031, Training Loss: 0.0371,  Validation loss: 0.0461\n",
            "Epoch: 37, time: 8.1165, Training Loss: 0.0364,  Validation loss: 0.0455\n",
            "Epoch: 38, time: 8.1025, Training Loss: 0.0353,  Validation loss: 0.0446\n",
            "Epoch: 39, time: 8.0870, Training Loss: 0.0344,  Validation loss: 0.0473\n",
            "Epoch: 40, time: 8.1091, Training Loss: 0.0338,  Validation loss: 0.0464\n",
            "Training time: 324.678254365921 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm_student_1= student_1_KD(3,3)\n",
        "mm_student_1.load_state_dict(torch.load(path+'student_1_KD.pth'))\n",
        "mm_student_1.to(device)\n",
        "\n",
        "mm_student_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(test_loader):\n",
        "        output,student_1 = mm_student_1(data_acc[:,:,0:3].to(device).float(),data_gyr[:,:,0:3].to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5,Z_6,Z_7=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_3=np.hstack([rmse,p])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVzh7GCMo_Xp",
        "outputId": "8e15fe27-5993-406d-dfcf-78396b28e304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3420, 100, 7)\n",
            "8.243782818317413\n",
            "10.972372442483902\n",
            "7.132858783006668\n",
            "5.1078543066978455\n",
            "3.6551859229803085\n",
            "8.061346411705017\n",
            "4.4807590544223785\n",
            "\n",
            "\n",
            "0.9005403385811627\n",
            "0.9109860943824564\n",
            "0.773819642725613\n",
            "0.9318123738225033\n",
            "0.8665864839071774\n",
            "0.9676504533699177\n",
            "0.9464481863485117\n",
            "Mean: 6.808 +/- 2.560\n",
            "Mean: 0.900 +/- 0.064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student Model-- 2. Foot+pelvis"
      ],
      "metadata": {
        "id": "MmFKq9UITrlk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0m07kPlTrlr"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GD_yaiuTrlr"
      },
      "outputs": [],
      "source": [
        "def train_mm_student_2(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data_acc=torch.cat((data_acc[:,:,0:3],data_acc[:,:,9:12]),dim=-1)\n",
        "            data_gyr=torch.cat((data_gyr[:,:,0:3],data_gyr[:,:,9:12]),dim=-1)\n",
        "            output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_Kinematics, data_EMG,data_JP, target in val_loader:\n",
        "                data_acc=torch.cat((data_acc[:,:,0:3],data_acc[:,:,9:12]),dim=-1)\n",
        "                data_gyr=torch.cat((data_gyr[:,:,0:3],data_gyr[:,:,9:12]),dim=-1)\n",
        "                output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Encoder Student Training"
      ],
      "metadata": {
        "id": "_c5Z_AIpTrls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBXPRY4cTrls"
      },
      "outputs": [],
      "source": [
        "class Encoder_1(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_1, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder_2(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_2, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ],
      "metadata": {
        "id": "bqeiHJ9iTrls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkGKiPgGTrls"
      },
      "outputs": [],
      "source": [
        "class student_2(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25):\n",
        "        super(student_2, self).__init__()\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,7)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "        # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "        # x_acc=torch.cat((x_acc_1,x_acc_2),dim=-1)\n",
        "        # x_gyr=torch.cat((x_gyr_1,x_gyr_2),dim=-1)\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "fe7ec2a0-1eba-4a5c-f24c-9c99c0aa449f",
        "id": "K4YwEU5CTrls"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 5.0477, Training Loss: 0.0983,  Validation loss: 0.0657\n",
            "Epoch: 2, time: 4.9881, Training Loss: 0.0643,  Validation loss: 0.0574\n",
            "Epoch: 3, time: 5.0051, Training Loss: 0.0587,  Validation loss: 0.0527\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-c499c3ae41e3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmm_student_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mm_student_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_student_2.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-c0c1d2ba62f0>\u001b[0m in \u001b[0;36mtrain_mm_student_2\u001b[0;34m(train_loader, learn_rate, EPOCHS, model, filename)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = student_2(6,6)\n",
        "\n",
        "mm_student_2 = train_mm_student_2(train_loader, lr,40,model,path+'_student_2.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7dLEwNfTrlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45dd3d03-19f0-4c0e-e7fd-b227da3c3e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3420, 100, 7)\n",
            "9.114701300859451\n",
            "11.177705228328705\n",
            "8.474799990653992\n",
            "6.234364211559296\n",
            "3.603503853082657\n",
            "9.082608669996262\n",
            "5.052555724978447\n",
            "\n",
            "\n",
            "0.8747713782179307\n",
            "0.9132991127170156\n",
            "0.7899431140064574\n",
            "0.9076074398712629\n",
            "0.8545303228046737\n",
            "0.9727320010654196\n",
            "0.9387202161872518\n",
            "Mean: 7.534 +/- 2.657\n",
            "Mean: 0.893 +/- 0.060\n"
          ]
        }
      ],
      "source": [
        "mm_student_2= student_2(6,6)\n",
        "mm_student_2.load_state_dict(torch.load(path+'_student_2.pth'))\n",
        "mm_student_2.to(device)\n",
        "\n",
        "mm_student_2.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(test_loader):\n",
        "        data_acc=torch.cat((data_acc[:,:,0:3],data_acc[:,:,9:12]),dim=-1)\n",
        "        data_gyr=torch.cat((data_gyr[:,:,0:3],data_gyr[:,:,9:12]),dim=-1)\n",
        "        output = mm_student_2(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5,Z_6,Z_7=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_4=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge+Sensor Distillation"
      ],
      "metadata": {
        "id": "cyY3Mq-cxksP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WQ7gzNuxksQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Knowledge distillation\"\"\"\n",
        "\n",
        "def train_student_2(train_loader, learn_rate, EPOCHS, model, filename, teacher):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion_2 =RMSELoss()\n",
        "    # criterion_2 =nn.MSELoss()\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    total_running_loss=0\n",
        "    running_loss=0\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data_acc_1=torch.cat((data_acc[:,:,0:3],data_acc[:,:,9:12]),dim=-1)\n",
        "            data_gyr_1=torch.cat((data_gyr[:,:,0:3],data_gyr[:,:,9:12]),dim=-1)\n",
        "            student_output, x_student_1= model(data_acc_1.to(device).float(),data_gyr_1.to(device).float())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_output,x_teacher_1= teacher(data_acc.to(device).float(),data_gyr.to(device).float(), data_EMG.to(device).float())\n",
        "\n",
        "            loss=criterion_2(student_output,target.to(device))+alpha*criterion_2(student_output,teacher_output)+beta*criterion_2(x_student_1,x_teacher_1)\n",
        "\n",
        "            loss_1=criterion_2(student_output,target.to(device))\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_Kinematics, data_EMG,data_JP, target in val_loader:\n",
        "                data_acc_1=torch.cat((data_acc[:,:,0:3],data_acc[:,:,9:12]),dim=-1)\n",
        "                data_gyr_1=torch.cat((data_gyr[:,:,0:3],data_gyr[:,:,9:12]),dim=-1)\n",
        "                output,student_1= model(data_acc_1.to(device).float(),data_gyr_1.to(device).float())\n",
        "                val_loss += criterion_2(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class student_2_KD(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25):\n",
        "        super(student_2_KD, self).__init__()\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc_kd=nn.Linear(2*128,2*128)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,7)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        x_KD=self.fc_kd(x)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x_KD"
      ],
      "metadata": {
        "id": "3qfdVIPuxksR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "student = student_2_KD(6,6)\n",
        "\n",
        "teacher_trained= teacher(12,12,11)\n",
        "teacher_trained.load_state_dict(torch.load(path+'_teacher.pth'))\n",
        "teacher_trained.to(device)\n",
        "\n",
        "\n",
        "student_KD= train_student_2(train_loader, lr,40, student,path+'student_2_KD.pth', teacher_trained)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "AZgBF_cbxksR",
        "outputId": "ce227f22-b5ca-48a8-bae0-d1e5895f1cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 7.7005, Training Loss: 0.0947,  Validation loss: 0.0622\n",
            "Epoch: 2, time: 7.6745, Training Loss: 0.0629,  Validation loss: 0.0554\n",
            "Epoch: 3, time: 7.7058, Training Loss: 0.0579,  Validation loss: 0.0528\n",
            "Epoch: 4, time: 7.7392, Training Loss: 0.0557,  Validation loss: 0.0529\n",
            "Epoch: 5, time: 7.7678, Training Loss: 0.0539,  Validation loss: 0.0505\n",
            "Epoch: 6, time: 7.7940, Training Loss: 0.0517,  Validation loss: 0.0490\n",
            "Epoch: 7, time: 7.8549, Training Loss: 0.0501,  Validation loss: 0.0478\n",
            "Epoch: 8, time: 7.8904, Training Loss: 0.0490,  Validation loss: 0.0460\n",
            "Epoch: 9, time: 7.9175, Training Loss: 0.0480,  Validation loss: 0.0456\n",
            "Epoch: 10, time: 7.9610, Training Loss: 0.0467,  Validation loss: 0.0451\n",
            "Epoch: 11, time: 7.9655, Training Loss: 0.0445,  Validation loss: 0.0451\n",
            "Epoch: 12, time: 7.9962, Training Loss: 0.0437,  Validation loss: 0.0442\n",
            "Epoch: 13, time: 7.9850, Training Loss: 0.0424,  Validation loss: 0.0437\n",
            "Epoch: 14, time: 7.9904, Training Loss: 0.0410,  Validation loss: 0.0422\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-1883dbf1a187>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstudent_KD\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_student_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'student_2_KD.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_trained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-1acdcb4d0254>\u001b[0m in \u001b[0;36mtrain_student_2\u001b[0;34m(train_loader, learn_rate, EPOCHS, model, filename, teacher)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm_student_1= student_2_KD(6,6)\n",
        "mm_student_1.load_state_dict(torch.load(path+'student_2_KD.pth'))\n",
        "mm_student_1.to(device)\n",
        "\n",
        "mm_student_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(test_loader):\n",
        "        data_acc=torch.cat((data_acc[:,:,0:3],data_acc[:,:,9:12]),dim=-1)\n",
        "        data_gyr=torch.cat((data_gyr[:,:,0:3],data_gyr[:,:,9:12]),dim=-1)\n",
        "        output,student_1 = mm_student_1(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5,Z_6,Z_7=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_5=np.hstack([rmse,p])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5q0Kd6jxksR",
        "outputId": "247a400b-a05b-489b-c9f7-9a0522ab3390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3420, 100, 7)\n",
            "7.74710550904274\n",
            "10.292401164770126\n",
            "6.441158801317215\n",
            "4.9640074372291565\n",
            "3.4805316478013992\n",
            "7.980266213417053\n",
            "4.413570463657379\n",
            "\n",
            "\n",
            "0.9112298642395699\n",
            "0.9038838521309949\n",
            "0.8108069034731041\n",
            "0.9315203770830011\n",
            "0.8667613081683566\n",
            "0.9716472709979739\n",
            "0.9499120344682619\n",
            "Mean: 6.474 +/- 2.379\n",
            "Mean: 0.907 +/- 0.054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student Model-- 3. Foot+pelvis+Shank"
      ],
      "metadata": {
        "id": "S-nzXUaqkv6K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXQdxO9Tkv6S"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyHRvdqVkv6S"
      },
      "outputs": [],
      "source": [
        "def train_mm_student_3(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data_acc=torch.cat((data_acc[:,:,0:6],data_acc[:,:,9:12]),dim=-1)\n",
        "            data_gyr=torch.cat((data_gyr[:,:,0:6],data_gyr[:,:,9:12]),dim=-1)\n",
        "            output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_Kinematics, data_EMG,data_JP, target in val_loader:\n",
        "                data_acc=torch.cat((data_acc[:,:,0:6],data_acc[:,:,9:12]),dim=-1)\n",
        "                data_gyr=torch.cat((data_gyr[:,:,0:6],data_gyr[:,:,9:12]),dim=-1)\n",
        "                output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Encoder Student Training"
      ],
      "metadata": {
        "id": "Qxw_KcPTkv6S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DZBviIRkv6S"
      },
      "outputs": [],
      "source": [
        "class Encoder_1(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_1, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder_2(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_2, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ],
      "metadata": {
        "id": "1iVFE3PKkv6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5gcL_U8kv6S"
      },
      "outputs": [],
      "source": [
        "class student_3(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25):\n",
        "        super(student_3, self).__init__()\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,7)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "        # x_acc=torch.cat((x_acc_1,x_acc_2),dim=-1)\n",
        "        # x_gyr=torch.cat((x_gyr_1,x_gyr_2),dim=-1)\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2677d963-1b91-40ac-9768-b98d2155b77c",
        "id": "eBWkb1MVkv6T"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 5.2018, Training Loss: 0.0883,  Validation loss: 0.0631\n",
            "Epoch: 2, time: 5.1250, Training Loss: 0.0612,  Validation loss: 0.0535\n",
            "Epoch: 3, time: 5.1433, Training Loss: 0.0553,  Validation loss: 0.0504\n",
            "Epoch: 4, time: 5.1537, Training Loss: 0.0530,  Validation loss: 0.0483\n",
            "Epoch: 5, time: 5.1708, Training Loss: 0.0504,  Validation loss: 0.0474\n",
            "Epoch: 6, time: 5.1670, Training Loss: 0.0492,  Validation loss: 0.0466\n",
            "Epoch: 7, time: 5.1844, Training Loss: 0.0481,  Validation loss: 0.0461\n",
            "Epoch: 8, time: 5.2128, Training Loss: 0.0463,  Validation loss: 0.0447\n",
            "Epoch: 9, time: 5.1978, Training Loss: 0.0460,  Validation loss: 0.0431\n",
            "Epoch: 10, time: 5.2173, Training Loss: 0.0442,  Validation loss: 0.0455\n",
            "Epoch: 11, time: 5.2152, Training Loss: 0.0442,  Validation loss: 0.0434\n",
            "Epoch: 12, time: 5.2308, Training Loss: 0.0408,  Validation loss: 0.0416\n",
            "Epoch: 13, time: 5.2444, Training Loss: 0.0402,  Validation loss: 0.0421\n",
            "Epoch: 14, time: 5.2650, Training Loss: 0.0393,  Validation loss: 0.0399\n",
            "Epoch: 15, time: 5.2669, Training Loss: 0.0371,  Validation loss: 0.0400\n",
            "Epoch: 16, time: 5.2627, Training Loss: 0.0374,  Validation loss: 0.0385\n",
            "Epoch: 17, time: 5.2606, Training Loss: 0.0355,  Validation loss: 0.0412\n",
            "Epoch: 18, time: 5.2811, Training Loss: 0.0341,  Validation loss: 0.0367\n",
            "Epoch: 19, time: 5.2777, Training Loss: 0.0331,  Validation loss: 0.0403\n",
            "Epoch: 20, time: 5.3369, Training Loss: 0.0320,  Validation loss: 0.0421\n",
            "Epoch: 21, time: 5.2847, Training Loss: 0.0330,  Validation loss: 0.0386\n",
            "Epoch: 22, time: 5.3002, Training Loss: 0.0313,  Validation loss: 0.0370\n",
            "Epoch: 23, time: 5.2928, Training Loss: 0.0300,  Validation loss: 0.0378\n",
            "Epoch: 24, time: 5.3031, Training Loss: 0.0296,  Validation loss: 0.0375\n",
            "Epoch: 25, time: 5.2859, Training Loss: 0.0285,  Validation loss: 0.0351\n",
            "Epoch: 26, time: 5.2960, Training Loss: 0.0278,  Validation loss: 0.0375\n",
            "Epoch: 27, time: 5.3176, Training Loss: 0.0272,  Validation loss: 0.0354\n",
            "Epoch: 28, time: 5.2852, Training Loss: 0.0261,  Validation loss: 0.0365\n",
            "Epoch: 29, time: 5.2904, Training Loss: 0.0251,  Validation loss: 0.0351\n",
            "Epoch: 30, time: 5.3127, Training Loss: 0.0262,  Validation loss: 0.0379\n",
            "Epoch: 31, time: 5.3460, Training Loss: 0.0257,  Validation loss: 0.0358\n",
            "Epoch: 32, time: 5.2772, Training Loss: 0.0248,  Validation loss: 0.0356\n",
            "Epoch: 33, time: 5.2806, Training Loss: 0.0239,  Validation loss: 0.0336\n",
            "Epoch: 34, time: 5.2794, Training Loss: 0.0236,  Validation loss: 0.0350\n",
            "Epoch: 35, time: 5.2891, Training Loss: 0.0225,  Validation loss: 0.0338\n",
            "Epoch: 36, time: 5.2710, Training Loss: 0.0222,  Validation loss: 0.0336\n",
            "Epoch: 37, time: 5.2700, Training Loss: 0.0218,  Validation loss: 0.0375\n",
            "Epoch: 38, time: 5.3070, Training Loss: 0.0217,  Validation loss: 0.0356\n",
            "Epoch: 39, time: 5.2758, Training Loss: 0.0227,  Validation loss: 0.0348\n",
            "Epoch: 40, time: 5.2771, Training Loss: 0.0207,  Validation loss: 0.0340\n",
            "Training time: 210.60567831993103 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = student_3(9,9)\n",
        "\n",
        "mm_student_3 = train_mm_student_3(train_loader, lr,40,model,path+'_student_3.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d5e623-9637-4023-fb3d-f9b37a67b83c",
        "id": "hD76m5u1kv6T"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3420, 100, 7)\n",
            "6.942823529243469\n",
            "8.130328357219696\n",
            "5.374911054968834\n",
            "4.3764326721429825\n",
            "3.362392634153366\n",
            "5.867745727300644\n",
            "3.7057165056467056\n",
            "\n",
            "\n",
            "0.9299336865282752\n",
            "0.9125893633307037\n",
            "0.887545695899486\n",
            "0.9461312904601025\n",
            "0.8732392316098252\n",
            "0.9830554494691893\n",
            "0.9605799868137439\n",
            "Mean: 5.394 +/- 1.738\n",
            "Mean: 0.928 +/- 0.039\n"
          ]
        }
      ],
      "source": [
        "mm_student_3= student_3(9,9)\n",
        "mm_student_3.load_state_dict(torch.load(path+'_student_3.pth'))\n",
        "mm_student_3.to(device)\n",
        "\n",
        "mm_student_3.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(test_loader):\n",
        "        data_acc=torch.cat((data_acc[:,:,0:6],data_acc[:,:,9:12]),dim=-1)\n",
        "        data_gyr=torch.cat((data_gyr[:,:,0:6],data_gyr[:,:,9:12]),dim=-1)\n",
        "        output = mm_student_3(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5,Z_6,Z_7=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_6=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge+Sensor Distillation"
      ],
      "metadata": {
        "id": "vXDErlYz01Ed"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "861u27XN01Ed"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Knowledge distillation\"\"\"\n",
        "\n",
        "def train_student_3(train_loader, learn_rate, EPOCHS, model, filename, teacher):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion_2 =RMSELoss()\n",
        "    # criterion_2 =nn.MSELoss()\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    total_running_loss=0\n",
        "    running_loss=0\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data_acc_1=torch.cat((data_acc[:,:,0:6],data_acc[:,:,9:12]),dim=-1)\n",
        "            data_gyr_1=torch.cat((data_gyr[:,:,0:6],data_gyr[:,:,9:12]),dim=-1)\n",
        "            student_output, x_student_1= model(data_acc_1.to(device).float(),data_gyr_1.to(device).float())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_output,x_teacher_1= teacher(data_acc.to(device).float(),data_gyr.to(device).float(), data_EMG.to(device).float())\n",
        "\n",
        "            loss=criterion_2(student_output,target.to(device))+alpha*criterion_2(student_output,teacher_output)+beta*criterion_2(x_student_1,x_teacher_1)\n",
        "\n",
        "            loss_1=criterion_2(student_output,target.to(device))\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_Kinematics, data_EMG,data_JP, target in val_loader:\n",
        "                data_acc_1=torch.cat((data_acc[:,:,0:6],data_acc[:,:,9:12]),dim=-1)\n",
        "                data_gyr_1=torch.cat((data_gyr[:,:,0:6],data_gyr[:,:,9:12]),dim=-1)\n",
        "                output,student_1= model(data_acc_1.to(device).float(),data_gyr_1.to(device).float())\n",
        "                val_loss += criterion_2(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class student_3_KD(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25):\n",
        "        super(student_3_KD, self).__init__()\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc_kd=nn.Linear(2*128,2*128)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,7)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        x_KD=self.fc_kd(x)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x_KD"
      ],
      "metadata": {
        "id": "4HHg_7ML01Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "student = student_3_KD(9,9)\n",
        "\n",
        "teacher_trained= teacher(12,12,11)\n",
        "teacher_trained.load_state_dict(torch.load(path+'_teacher.pth'))\n",
        "teacher_trained.to(device)\n",
        "\n",
        "\n",
        "student_KD= train_student_3(train_loader, lr,40, student,path+'student_3_KD.pth', teacher_trained)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e021ae-12ac-4511-cba2-d10273f0a88e",
        "id": "bj_jcX4g01Ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 7.8828, Training Loss: 0.0893,  Validation loss: 0.0583\n",
            "Epoch: 2, time: 7.7960, Training Loss: 0.0594,  Validation loss: 0.0511\n",
            "Epoch: 3, time: 7.8091, Training Loss: 0.0535,  Validation loss: 0.0516\n",
            "Epoch: 4, time: 7.9031, Training Loss: 0.0528,  Validation loss: 0.0474\n",
            "Epoch: 5, time: 7.9140, Training Loss: 0.0505,  Validation loss: 0.0465\n",
            "Epoch: 6, time: 8.0448, Training Loss: 0.0493,  Validation loss: 0.0468\n",
            "Epoch: 7, time: 8.0028, Training Loss: 0.0475,  Validation loss: 0.0458\n",
            "Epoch: 8, time: 8.0022, Training Loss: 0.0457,  Validation loss: 0.0460\n",
            "Epoch: 9, time: 8.1306, Training Loss: 0.0450,  Validation loss: 0.0435\n",
            "Epoch: 10, time: 8.0383, Training Loss: 0.0431,  Validation loss: 0.0410\n",
            "Epoch: 11, time: 8.0347, Training Loss: 0.0412,  Validation loss: 0.0421\n",
            "Epoch: 12, time: 8.0205, Training Loss: 0.0402,  Validation loss: 0.0397\n",
            "Epoch: 13, time: 8.0330, Training Loss: 0.0389,  Validation loss: 0.0433\n",
            "Epoch: 14, time: 8.0786, Training Loss: 0.0372,  Validation loss: 0.0413\n",
            "Epoch: 15, time: 8.0911, Training Loss: 0.0370,  Validation loss: 0.0418\n",
            "Epoch: 16, time: 8.1410, Training Loss: 0.0356,  Validation loss: 0.0384\n",
            "Epoch: 17, time: 8.1693, Training Loss: 0.0342,  Validation loss: 0.0381\n",
            "Epoch: 18, time: 8.1980, Training Loss: 0.0318,  Validation loss: 0.0376\n",
            "Epoch: 19, time: 8.1672, Training Loss: 0.0306,  Validation loss: 0.0375\n",
            "Epoch: 20, time: 8.1456, Training Loss: 0.0304,  Validation loss: 0.0364\n",
            "Epoch: 21, time: 8.1755, Training Loss: 0.0316,  Validation loss: 0.0370\n",
            "Epoch: 22, time: 8.1264, Training Loss: 0.0294,  Validation loss: 0.0362\n",
            "Epoch: 23, time: 8.0969, Training Loss: 0.0284,  Validation loss: 0.0361\n",
            "Epoch: 24, time: 8.0974, Training Loss: 0.0279,  Validation loss: 0.0352\n",
            "Epoch: 25, time: 8.1185, Training Loss: 0.0269,  Validation loss: 0.0345\n",
            "Epoch: 26, time: 8.1209, Training Loss: 0.0267,  Validation loss: 0.0367\n",
            "Epoch: 27, time: 8.1432, Training Loss: 0.0250,  Validation loss: 0.0344\n",
            "Epoch: 28, time: 8.1662, Training Loss: 0.0255,  Validation loss: 0.0364\n",
            "Epoch: 29, time: 8.1439, Training Loss: 0.0249,  Validation loss: 0.0357\n",
            "Epoch: 30, time: 8.1674, Training Loss: 0.0232,  Validation loss: 0.0346\n",
            "Epoch: 31, time: 8.1633, Training Loss: 0.0228,  Validation loss: 0.0332\n",
            "Epoch: 32, time: 8.1365, Training Loss: 0.0224,  Validation loss: 0.0345\n",
            "Epoch: 33, time: 8.1417, Training Loss: 0.0249,  Validation loss: 0.0360\n",
            "Epoch: 34, time: 8.1816, Training Loss: 0.0237,  Validation loss: 0.0356\n",
            "Epoch: 35, time: 8.1863, Training Loss: 0.0237,  Validation loss: 0.0337\n",
            "Epoch: 36, time: 8.1249, Training Loss: 0.0236,  Validation loss: 0.0347\n",
            "Epoch: 37, time: 8.1179, Training Loss: 0.0230,  Validation loss: 0.0351\n",
            "Epoch: 38, time: 8.1104, Training Loss: 0.0230,  Validation loss: 0.0342\n",
            "Epoch: 39, time: 8.1025, Training Loss: 0.0207,  Validation loss: 0.0341\n",
            "Epoch: 40, time: 8.1365, Training Loss: 0.0201,  Validation loss: 0.0330\n",
            "Training time: 323.77487993240356 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm_student_1= student_3_KD(9,9)\n",
        "mm_student_1.load_state_dict(torch.load(path+'student_3_KD.pth'))\n",
        "mm_student_1.to(device)\n",
        "\n",
        "mm_student_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(test_loader):\n",
        "        data_acc=torch.cat((data_acc[:,:,0:6],data_acc[:,:,9:12]),dim=-1)\n",
        "        data_gyr=torch.cat((data_gyr[:,:,0:6],data_gyr[:,:,9:12]),dim=-1)\n",
        "        output,student_1 = mm_student_1(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5,Z_6,Z_7=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_7=np.hstack([rmse,p])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40809f38-0c95-4580-ddc4-5fd32336cade",
        "id": "V7h_glhS01Ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3420, 100, 7)\n",
            "7.340579479932785\n",
            "10.100262612104416\n",
            "5.351198464632034\n",
            "4.650748148560524\n",
            "3.6068737506866455\n",
            "5.379888415336609\n",
            "3.4117117524147034\n",
            "\n",
            "\n",
            "0.9284846243880213\n",
            "0.9237486437633137\n",
            "0.8868820742887492\n",
            "0.9504884373914996\n",
            "0.8704828129615726\n",
            "0.9863332983728698\n",
            "0.9669271587854319\n",
            "Mean: 5.692 +/- 2.345\n",
            "Mean: 0.930 +/- 0.042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student Model-- 4. Foot+pelvis+Shank+Thigh"
      ],
      "metadata": {
        "id": "4FCwGDTxnDz4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7lJrK8dnDz_"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORd5A3HBnDz_"
      },
      "outputs": [],
      "source": [
        "def train_mm_student_4(train_loader, learn_rate, EPOCHS, model,filename):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    # Defining loss function and optimizer\n",
        "    criterion =RMSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data_acc=torch.cat((data_acc[:,:,0:9],data_acc[:,:,9:12]),dim=-1)\n",
        "            data_gyr=torch.cat((data_gyr[:,:,0:9],data_gyr[:,:,9:12]),dim=-1)\n",
        "            output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "\n",
        "            loss = criterion(output, target.to(device).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_Kinematics, data_EMG,data_JP, target in val_loader:\n",
        "                data_acc=torch.cat((data_acc[:,:,0:9],data_acc[:,:,9:12]),dim=-1)\n",
        "                data_gyr=torch.cat((data_gyr[:,:,0:9],data_gyr[:,:,9:12]),dim=-1)\n",
        "                output= model(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "                val_loss += criterion(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Encoder Student Training"
      ],
      "metadata": {
        "id": "0GqVXImunDz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YgQpww1nDz_"
      },
      "outputs": [],
      "source": [
        "class Encoder_1(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_1, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder_2(nn.Module):\n",
        "    def __init__(self, input_dim, dropout):\n",
        "        super(Encoder_2, self).__init__()\n",
        "        self.lstm_1 = nn.GRU(input_dim, 128, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.lstm_2 = nn.GRU(256, 64, bidirectional=True, batch_first=True, dropout=0.0)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 32)\n",
        "        self.dropout_1=nn.Dropout(dropout)\n",
        "        self.dropout_2=nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_1, _ = self.lstm_1(x)\n",
        "        out_1=self.dropout_1(out_1)\n",
        "        out_2, _ = self.lstm_2(out_1)\n",
        "        out_2=self.dropout_2(out_2)\n",
        "\n",
        "        return out_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingModule(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GatingModule, self).__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(2*input_size, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Apply gating mechanism\n",
        "        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n",
        "\n",
        "        # Scale the inputs based on the gate output\n",
        "        gated_input1 = input1 * gate_output\n",
        "        gated_input2 = input2 * (1 - gate_output)\n",
        "\n",
        "        # Combine the gated inputs\n",
        "        output = gated_input1 + gated_input2\n",
        "        return output"
      ],
      "metadata": {
        "id": "xAKQ7MMYnDz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcTyTvHcnDz_"
      },
      "outputs": [],
      "source": [
        "class student_4(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25):\n",
        "        super(student_4, self).__init__()\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,7)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "        # x_acc=torch.cat((x_acc_1,x_acc_2),dim=-1)\n",
        "        # x_gyr=torch.cat((x_gyr_1,x_gyr_2),dim=-1)\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5edce1a-cb05-4adf-eb45-2549a64dd34d",
        "id": "QzuBnq3WnDz_"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 5.2881, Training Loss: 0.0808,  Validation loss: 0.0548\n",
            "Epoch: 2, time: 5.2562, Training Loss: 0.0567,  Validation loss: 0.0490\n",
            "Epoch: 3, time: 5.3016, Training Loss: 0.0523,  Validation loss: 0.0469\n",
            "Epoch: 4, time: 5.3499, Training Loss: 0.0505,  Validation loss: 0.0467\n",
            "Epoch: 5, time: 5.3951, Training Loss: 0.0484,  Validation loss: 0.0450\n",
            "Epoch: 6, time: 5.4106, Training Loss: 0.0474,  Validation loss: 0.0452\n",
            "Epoch: 7, time: 5.3821, Training Loss: 0.0459,  Validation loss: 0.0428\n",
            "Epoch: 8, time: 5.3236, Training Loss: 0.0446,  Validation loss: 0.0419\n",
            "Epoch: 9, time: 5.2961, Training Loss: 0.0439,  Validation loss: 0.0416\n",
            "Epoch: 10, time: 5.2517, Training Loss: 0.0421,  Validation loss: 0.0411\n",
            "Epoch: 11, time: 5.2518, Training Loss: 0.0410,  Validation loss: 0.0406\n",
            "Epoch: 12, time: 5.2142, Training Loss: 0.0397,  Validation loss: 0.0400\n",
            "Epoch: 13, time: 5.2042, Training Loss: 0.0380,  Validation loss: 0.0403\n",
            "Epoch: 14, time: 5.2156, Training Loss: 0.0370,  Validation loss: 0.0410\n",
            "Epoch: 15, time: 5.2198, Training Loss: 0.0363,  Validation loss: 0.0392\n",
            "Epoch: 16, time: 5.2327, Training Loss: 0.0347,  Validation loss: 0.0378\n",
            "Epoch: 17, time: 5.2532, Training Loss: 0.0332,  Validation loss: 0.0368\n",
            "Epoch: 18, time: 5.2682, Training Loss: 0.0330,  Validation loss: 0.0377\n",
            "Epoch: 19, time: 5.2891, Training Loss: 0.0325,  Validation loss: 0.0361\n",
            "Epoch: 20, time: 5.2939, Training Loss: 0.0301,  Validation loss: 0.0359\n",
            "Epoch: 21, time: 5.3107, Training Loss: 0.0302,  Validation loss: 0.0350\n",
            "Epoch: 22, time: 5.3168, Training Loss: 0.0293,  Validation loss: 0.0364\n",
            "Epoch: 23, time: 5.3150, Training Loss: 0.0277,  Validation loss: 0.0369\n",
            "Epoch: 24, time: 5.3149, Training Loss: 0.0286,  Validation loss: 0.0351\n",
            "Epoch: 25, time: 5.2986, Training Loss: 0.0258,  Validation loss: 0.0330\n",
            "Epoch: 26, time: 5.2947, Training Loss: 0.0247,  Validation loss: 0.0339\n",
            "Epoch: 27, time: 5.2838, Training Loss: 0.0272,  Validation loss: 0.0347\n",
            "Epoch: 28, time: 5.2703, Training Loss: 0.0245,  Validation loss: 0.0343\n",
            "Epoch: 29, time: 5.2667, Training Loss: 0.0237,  Validation loss: 0.0330\n",
            "Epoch: 30, time: 5.2638, Training Loss: 0.0233,  Validation loss: 0.0329\n",
            "Epoch: 31, time: 5.2401, Training Loss: 0.0221,  Validation loss: 0.0335\n",
            "Epoch: 32, time: 5.2589, Training Loss: 0.0219,  Validation loss: 0.0314\n",
            "Epoch: 33, time: 5.2490, Training Loss: 0.0211,  Validation loss: 0.0343\n",
            "Epoch: 34, time: 5.2575, Training Loss: 0.0209,  Validation loss: 0.0328\n",
            "Epoch: 35, time: 5.2782, Training Loss: 0.0215,  Validation loss: 0.0332\n",
            "Epoch: 36, time: 5.2843, Training Loss: 0.0212,  Validation loss: 0.0314\n",
            "Epoch: 37, time: 5.2788, Training Loss: 0.0205,  Validation loss: 0.0312\n",
            "Epoch: 38, time: 5.2879, Training Loss: 0.0199,  Validation loss: 0.0310\n",
            "Epoch: 39, time: 5.2911, Training Loss: 0.0193,  Validation loss: 0.0310\n",
            "Epoch: 40, time: 5.2902, Training Loss: 0.0194,  Validation loss: 0.0315\n",
            "Training time: 211.84201169013977 seconds\n"
          ]
        }
      ],
      "source": [
        "lr = 0.001\n",
        "model = student_4(12,12)\n",
        "\n",
        "mm_student_4 = train_mm_student_4(train_loader, lr,40,model,path+'_student_4.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a4122fe-5fec-4950-af7b-93d5154d2645",
        "id": "4icckZbqnD0A"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3420, 100, 7)\n",
            "7.0999957621097565\n",
            "7.528646290302277\n",
            "4.745883867144585\n",
            "4.146308079361916\n",
            "3.4655317664146423\n",
            "5.355195328593254\n",
            "3.7266936153173447\n",
            "\n",
            "\n",
            "0.9096207635211805\n",
            "0.9276250837890206\n",
            "0.9013756224337864\n",
            "0.9487737614442834\n",
            "0.8920406691517062\n",
            "0.9887288033907642\n",
            "0.9604332270585669\n",
            "Mean: 5.153 +/- 1.609\n",
            "Mean: 0.933 +/- 0.035\n"
          ]
        }
      ],
      "source": [
        "mm_student_4= student_4(12,12)\n",
        "mm_student_4.load_state_dict(torch.load(path+'_student_4.pth'))\n",
        "mm_student_4.to(device)\n",
        "\n",
        "mm_student_4.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(test_loader):\n",
        "        data_acc=torch.cat((data_acc[:,:,0:9],data_acc[:,:,9:12]),dim=-1)\n",
        "        data_gyr=torch.cat((data_gyr[:,:,0:9],data_gyr[:,:,9:12]),dim=-1)\n",
        "        output = mm_student_4(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5,Z_6,Z_7=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_8=np.hstack([rmse,p])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge+Sensor Distillation"
      ],
      "metadata": {
        "id": "gZu22Q6e2Mhw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHS-CXaR2Mhx"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Knowledge distillation\"\"\"\n",
        "\n",
        "def train_student_4(train_loader, learn_rate, EPOCHS, model, filename, teacher):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "\n",
        "    # Defining loss function and optimizer\n",
        "    criterion_2 =RMSELoss()\n",
        "    # criterion_2 =nn.MSELoss()\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    total_running_loss=0\n",
        "    running_loss=0\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data_acc_1=torch.cat((data_acc[:,:,0:9],data_acc[:,:,9:12]),dim=-1)\n",
        "            data_gyr_1=torch.cat((data_gyr[:,:,0:9],data_gyr[:,:,9:12]),dim=-1)\n",
        "            student_output, x_student_1= model(data_acc_1.to(device).float(),data_gyr_1.to(device).float())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_output,x_teacher_1= teacher(data_acc.to(device).float(),data_gyr.to(device).float(), data_EMG.to(device).float())\n",
        "\n",
        "            loss=criterion_2(student_output,target.to(device))+alpha*criterion_2(student_output,teacher_output)+beta*criterion_2(x_student_1,x_teacher_1)\n",
        "\n",
        "            loss_1=criterion_2(student_output,target.to(device))\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss_1.item()\n",
        "\n",
        "        train_loss=running_loss/len(train_loader)\n",
        "\n",
        "       # Validate\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, data_acc, data_gyr, data_Kinematics, data_EMG,data_JP, target in val_loader:\n",
        "                data_acc_1=torch.cat((data_acc[:,:,0:9],data_acc[:,:,9:12]),dim=-1)\n",
        "                data_gyr_1=torch.cat((data_gyr[:,:,0:9],data_gyr[:,:,9:12]),dim=-1)\n",
        "                output,student_1= model(data_acc_1.to(device).float(),data_gyr_1.to(device).float())\n",
        "                val_loss += criterion_2(output, target.to(device).float())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_training_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        torch.set_printoptions(precision=4)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, time: {epoch_training_time:.4f}, Training Loss: {train_loss:.4f},  Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "        running_loss=0\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "                # Check if the validation loss has improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping if the validation loss hasn't improved for `patience` epochs\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training time: {training_time} seconds\")\n",
        "\n",
        "\n",
        "    # # Save the trained model\n",
        "    # torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class student_4_KD(nn.Module):\n",
        "    def __init__(self, input_acc, input_gyr, drop_prob=0.25):\n",
        "        super(student_4_KD, self).__init__()\n",
        "\n",
        "        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n",
        "        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n",
        "\n",
        "        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n",
        "        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n",
        "\n",
        "        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n",
        "        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n",
        "\n",
        "        self.fc_kd=nn.Linear(2*128,2*128)\n",
        "\n",
        "        self.fc = nn.Linear(2*2*128+128,7)\n",
        "        self.dropout=nn.Dropout(p=0.05)\n",
        "\n",
        "        self.gate_1=GatingModule(128)\n",
        "        self.gate_2=GatingModule(128)\n",
        "\n",
        "\n",
        "               # Define the gating network\n",
        "        self.weighted_feat = nn.Sequential(\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        self.attention=nn.MultiheadAttention(2*128,4,batch_first=True)\n",
        "        self.gating_net = nn.Sequential(nn.Linear(128*2, 2*128), nn.Sigmoid())\n",
        "        self.gating_net_1 = nn.Sequential(nn.Linear(2*2*128+128, 2*2*128+128), nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x_acc, x_gyr):\n",
        "\n",
        "        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n",
        "        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n",
        "\n",
        "        x_acc_1=self.BN_acc(x_acc_1)\n",
        "        x_gyr_1=self.BN_gyr(x_gyr_1)\n",
        "\n",
        "        x_acc_2=x_acc_1.view(-1, w, x_acc_1.size(-1))\n",
        "        x_gyr_2=x_gyr_1.view(-1, w, x_gyr_1.size(-1))\n",
        "\n",
        "        x_acc_1=self.encoder_1_acc(x_acc_2)\n",
        "        x_gyr_1=self.encoder_1_gyr(x_gyr_2)\n",
        "\n",
        "        x_acc_2=self.encoder_2_acc(x_acc_2)\n",
        "        x_gyr_2=self.encoder_2_gyr(x_gyr_2)\n",
        "\n",
        "\n",
        "        x_acc=self.gate_1(x_acc_1,x_acc_2)\n",
        "        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n",
        "\n",
        "        x=torch.cat((x_acc,x_gyr),dim=-1)\n",
        "\n",
        "        x_KD=self.fc_kd(x)\n",
        "\n",
        "        out_1, attn_output_weights=self.attention(x,x,x)\n",
        "\n",
        "        gating_weights = self.gating_net(x)\n",
        "        out_2=gating_weights*x\n",
        "\n",
        "        weights_1 = self.weighted_feat(x[:,:,0:128])\n",
        "        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n",
        "        x_1=weights_1*x[:,:,0:128]\n",
        "        x_2=weights_2*x[:,:,128:2*128]\n",
        "        out_3=x_1+x_2\n",
        "\n",
        "\n",
        "        out=torch.cat((out_1,out_2,out_3),dim=-1)\n",
        "\n",
        "        gating_weights_1 = self.gating_net_1(out)\n",
        "        out=gating_weights_1*out\n",
        "\n",
        "        out=self.fc(out)\n",
        "\n",
        "        return out,x_KD"
      ],
      "metadata": {
        "id": "dQ_LbzvU2Mhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "student = student_4_KD(12,12)\n",
        "\n",
        "teacher_trained= teacher(12,12,11)\n",
        "teacher_trained.load_state_dict(torch.load(path+'_teacher.pth'))\n",
        "teacher_trained.to(device)\n",
        "\n",
        "\n",
        "student_KD= train_student_4(train_loader, lr,40, student,path+'student_4_KD.pth', teacher_trained)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c27247af-6b32-4162-9584-965895f2447f",
        "id": "Cq5Aa9Em2Mhx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, time: 8.2220, Training Loss: 0.0827,  Validation loss: 0.0561\n",
            "Epoch: 2, time: 8.2502, Training Loss: 0.0569,  Validation loss: 0.0507\n",
            "Epoch: 3, time: 8.3505, Training Loss: 0.0527,  Validation loss: 0.0490\n",
            "Epoch: 4, time: 8.3731, Training Loss: 0.0500,  Validation loss: 0.0457\n",
            "Epoch: 5, time: 8.2600, Training Loss: 0.0477,  Validation loss: 0.0447\n",
            "Epoch: 6, time: 8.1614, Training Loss: 0.0466,  Validation loss: 0.0432\n",
            "Epoch: 7, time: 8.0750, Training Loss: 0.0448,  Validation loss: 0.0433\n",
            "Epoch: 8, time: 8.0297, Training Loss: 0.0431,  Validation loss: 0.0417\n",
            "Epoch: 9, time: 8.0239, Training Loss: 0.0407,  Validation loss: 0.0418\n",
            "Epoch: 10, time: 8.0444, Training Loss: 0.0397,  Validation loss: 0.0426\n",
            "Epoch: 11, time: 8.0676, Training Loss: 0.0388,  Validation loss: 0.0439\n",
            "Epoch: 12, time: 8.1267, Training Loss: 0.0378,  Validation loss: 0.0391\n",
            "Epoch: 13, time: 8.1897, Training Loss: 0.0349,  Validation loss: 0.0368\n",
            "Epoch: 14, time: 8.2295, Training Loss: 0.0335,  Validation loss: 0.0364\n",
            "Epoch: 15, time: 8.1953, Training Loss: 0.0328,  Validation loss: 0.0372\n",
            "Epoch: 16, time: 8.1911, Training Loss: 0.0313,  Validation loss: 0.0394\n",
            "Epoch: 17, time: 8.1805, Training Loss: 0.0293,  Validation loss: 0.0369\n",
            "Epoch: 18, time: 8.1299, Training Loss: 0.0297,  Validation loss: 0.0354\n",
            "Epoch: 19, time: 8.1166, Training Loss: 0.0292,  Validation loss: 0.0372\n",
            "Epoch: 20, time: 8.1057, Training Loss: 0.0288,  Validation loss: 0.0368\n",
            "Epoch: 21, time: 8.1115, Training Loss: 0.0271,  Validation loss: 0.0340\n",
            "Epoch: 22, time: 8.1236, Training Loss: 0.0267,  Validation loss: 0.0339\n",
            "Epoch: 23, time: 8.1491, Training Loss: 0.0239,  Validation loss: 0.0333\n",
            "Epoch: 24, time: 8.1793, Training Loss: 0.0246,  Validation loss: 0.0367\n",
            "Epoch: 25, time: 8.1883, Training Loss: 0.0263,  Validation loss: 0.0331\n",
            "Epoch: 26, time: 8.1932, Training Loss: 0.0231,  Validation loss: 0.0314\n",
            "Epoch: 27, time: 8.1554, Training Loss: 0.0225,  Validation loss: 0.0324\n",
            "Epoch: 28, time: 8.1570, Training Loss: 0.0245,  Validation loss: 0.0329\n",
            "Epoch: 29, time: 8.1602, Training Loss: 0.0219,  Validation loss: 0.0341\n",
            "Epoch: 30, time: 8.1313, Training Loss: 0.0215,  Validation loss: 0.0315\n",
            "Epoch: 31, time: 8.1365, Training Loss: 0.0207,  Validation loss: 0.0309\n",
            "Epoch: 32, time: 8.1407, Training Loss: 0.0211,  Validation loss: 0.0326\n",
            "Epoch: 33, time: 8.1333, Training Loss: 0.0217,  Validation loss: 0.0328\n",
            "Epoch: 34, time: 8.1257, Training Loss: 0.0212,  Validation loss: 0.0349\n",
            "Epoch: 35, time: 8.1369, Training Loss: 0.0211,  Validation loss: 0.0322\n",
            "Epoch: 36, time: 8.1309, Training Loss: 0.0212,  Validation loss: 0.0319\n",
            "Epoch: 37, time: 8.1430, Training Loss: 0.0192,  Validation loss: 0.0319\n",
            "Epoch: 38, time: 8.1497, Training Loss: 0.0185,  Validation loss: 0.0315\n",
            "Epoch: 39, time: 8.1359, Training Loss: 0.0188,  Validation loss: 0.0315\n",
            "Epoch: 40, time: 8.1354, Training Loss: 0.0178,  Validation loss: 0.0320\n",
            "Training time: 326.60987877845764 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm_student_1= student_4_KD(12,12)\n",
        "mm_student_1.load_state_dict(torch.load(path+'student_4_KD.pth'))\n",
        "mm_student_1.to(device)\n",
        "\n",
        "mm_student_1.eval()\n",
        "\n",
        "# iterate through batches of test data\n",
        "with torch.no_grad():\n",
        "    for i, (data, data_acc, data_gyr, data_Kinematics,data_EMG,data_JP, target) in enumerate(test_loader):\n",
        "        data_acc=torch.cat((data_acc[:,:,0:9],data_acc[:,:,9:12]),dim=-1)\n",
        "        data_gyr=torch.cat((data_gyr[:,:,0:9],data_gyr[:,:,9:12]),dim=-1)\n",
        "        output,student_1 = mm_student_1(data_acc.to(device).float(),data_gyr.to(device).float())\n",
        "        if i==0:\n",
        "          yhat_5=output\n",
        "          test_target=target\n",
        "\n",
        "        yhat_5=torch.cat((yhat_5,output),dim=0)\n",
        "        test_target=torch.cat((test_target,target),dim=0)\n",
        "\n",
        "        # clear memory\n",
        "        del data, target,output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "yhat_4 = yhat_5.detach().cpu().numpy()\n",
        "test_target = test_target.detach().cpu().numpy()\n",
        "print(yhat_4.shape)\n",
        "\n",
        "rmse, p, Z_1,Z_2,Z_3,Z_4,Z_5,Z_6,Z_7=RMSE_prediction(yhat_4,test_target,s)\n",
        "\n",
        "ablation_9=np.hstack([rmse,p])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db9103e0-cf55-4616-e4f7-ddb6945e81b4",
        "id": "KAO_TfIL2Mhy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3420, 100, 7)\n",
            "6.2536828219890594\n",
            "9.800749272108078\n",
            "4.870125278830528\n",
            "4.995094984769821\n",
            "3.5416338592767715\n",
            "5.722145363688469\n",
            "3.725144639611244\n",
            "\n",
            "\n",
            "0.9180085336468797\n",
            "0.9262689072762963\n",
            "0.904872570789025\n",
            "0.9476765360591649\n",
            "0.8689431866533748\n",
            "0.9881302962763376\n",
            "0.9625817333532871\n",
            "Mean: 5.558 +/- 2.111\n",
            "Mean: 0.931 +/- 0.039\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TrXnoV0Js5CO",
        "3mq0s3oBqlJ5",
        "zM9iGjQ6uXU-",
        "iP_eDnJwrKCC",
        "9FG-HuNBV52f",
        "FTmA6QwQNiMn",
        "MmFKq9UITrlk",
        "C0m07kPlTrlr",
        "S-nzXUaqkv6K",
        "zXQdxO9Tkv6S",
        "4FCwGDTxnDz4",
        "N7lJrK8dnDz_"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}